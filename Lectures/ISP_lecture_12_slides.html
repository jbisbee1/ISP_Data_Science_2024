<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Text, Tweets, and Sentiment</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Bisbee" />
    <script src="libs/header-attrs-2.27/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Text, Tweets, and Sentiment
]
.subtitle[
## Part 3
]
.author[
### Prof. Bisbee
]
.institute[
### Seoul National University
]
.date[
### Slides Updated: 2024-07-16
]

---




---

# Returning to Trump


``` r
require(tidyverse)
tweet_words &lt;- read_rds(file="https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/Trump_tweet_words.Rds")
tweet_words &lt;- tweet_words %&gt;% mutate(PostPresident = Tweeting.date &gt; as.Date('2016-11-06'))
```

---

# Log-Odds

- **Odds**: Probability a word is used pre/post presidency
  
- **Log**: Useful for removing skew in data!
  
--

- Interactive code time!

---

# Odds Step 1


``` r
(odds1 &lt;- tweet_words %&gt;%
  count(word, PostPresident) %&gt;%
  filter(sum(n) &gt;= 5) %&gt;%
  spread(PostPresident, n, fill = 0) %&gt;%
  ungroup() %&gt;%
  mutate(totFALSE = sum(`FALSE`),
         totTRUE = sum(`TRUE`)))
```

```
## # A tibble: 45,221 × 5
##    word      `FALSE` `TRUE` totFALSE totTRUE
##    &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;
##  1 a               6     27   189217  257487
##  2 aa              1      2   189217  257487
##  3 aaa            11      1   189217  257487
##  4 aamp            1      0   189217  257487
##  5 aand            0      1   189217  257487
##  6 aaron           2      1   189217  257487
##  7 ab              1      2   189217  257487
##  8 abaco           0      1   189217  257487
##  9 abandon         6      8   189217  257487
## 10 abandoned      13     11   189217  257487
## # ℹ 45,211 more rows
```

---

# Odds Step 2


``` r
(odds2 &lt;- odds1 %&gt;%
  mutate(propFALSE = (`FALSE` + 1) / (totFALSE + 1),
         propTRUE = (`TRUE` + 1) / (totTRUE + 1)))
```

```
## # A tibble: 45,221 × 7
##    word   `FALSE` `TRUE` totFALSE totTRUE propFALSE propTRUE
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 a            6     27   189217  257487   3.70e-5  1.09e-4
##  2 aa           1      2   189217  257487   1.06e-5  1.17e-5
##  3 aaa         11      1   189217  257487   6.34e-5  7.77e-6
##  4 aamp         1      0   189217  257487   1.06e-5  3.88e-6
##  5 aand         0      1   189217  257487   5.28e-6  7.77e-6
##  6 aaron        2      1   189217  257487   1.59e-5  7.77e-6
##  7 ab           1      2   189217  257487   1.06e-5  1.17e-5
##  8 abaco        0      1   189217  257487   5.28e-6  7.77e-6
##  9 aband…       6      8   189217  257487   3.70e-5  3.50e-5
## 10 aband…      13     11   189217  257487   7.40e-5  4.66e-5
## # ℹ 45,211 more rows
```

---

# Odds Step 3


``` r
(odds3 &lt;- odds2 %&gt;%
  mutate(odds = propTRUE / propFALSE))
```

```
## # A tibble: 45,221 × 8
##    word   `FALSE` `TRUE` totFALSE totTRUE propFALSE propTRUE
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 a            6     27   189217  257487   3.70e-5  1.09e-4
##  2 aa           1      2   189217  257487   1.06e-5  1.17e-5
##  3 aaa         11      1   189217  257487   6.34e-5  7.77e-6
##  4 aamp         1      0   189217  257487   1.06e-5  3.88e-6
##  5 aand         0      1   189217  257487   5.28e-6  7.77e-6
##  6 aaron        2      1   189217  257487   1.59e-5  7.77e-6
##  7 ab           1      2   189217  257487   1.06e-5  1.17e-5
##  8 abaco        0      1   189217  257487   5.28e-6  7.77e-6
##  9 aband…       6      8   189217  257487   3.70e-5  3.50e-5
## 10 aband…      13     11   189217  257487   7.40e-5  4.66e-5
## # ℹ 45,211 more rows
## # ℹ 1 more variable: odds &lt;dbl&gt;
```

---

# Why log?


``` r
odds3 %&gt;%
  ggplot(aes(x = odds)) + 
  geom_histogram()
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-6-1.svg" style="display: block; margin: auto;" /&gt;

---

# Why log?


``` r
odds3 %&gt;%
  ggplot(aes(x = odds)) + 
  geom_histogram(bins = 15) + 
  scale_x_log10()
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-7-1.svg" style="display: block; margin: auto;" /&gt;

---

# Odds Step 4


``` r
(prepost_logodds &lt;- odds3 %&gt;%
  mutate(logodds = log(odds)))
```

```
## # A tibble: 45,221 × 9
##    word   `FALSE` `TRUE` totFALSE totTRUE propFALSE propTRUE
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 a            6     27   189217  257487   3.70e-5  1.09e-4
##  2 aa           1      2   189217  257487   1.06e-5  1.17e-5
##  3 aaa         11      1   189217  257487   6.34e-5  7.77e-6
##  4 aamp         1      0   189217  257487   1.06e-5  3.88e-6
##  5 aand         0      1   189217  257487   5.28e-6  7.77e-6
##  6 aaron        2      1   189217  257487   1.59e-5  7.77e-6
##  7 ab           1      2   189217  257487   1.06e-5  1.17e-5
##  8 abaco        0      1   189217  257487   5.28e-6  7.77e-6
##  9 aband…       6      8   189217  257487   3.70e-5  3.50e-5
## 10 aband…      13     11   189217  257487   7.40e-5  4.66e-5
## # ℹ 45,211 more rows
## # ℹ 2 more variables: odds &lt;dbl&gt;, logodds &lt;dbl&gt;
```

---

# Effect of becoming president


``` r
p &lt;- prepost_logodds %&gt;%
  group_by(logodds &gt; 0) %&gt;%
  top_n(15, abs(logodds)) %&gt;%
  ungroup() %&gt;%
  mutate(word = reorder(word, logodds)) %&gt;%
  ggplot(aes(word, logodds, fill = logodds &lt; 0)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Post-President/Pre-President log ratio") +
  scale_fill_manual(name = "", labels = c("President", "Pre-President"),
                    values = c("red", "lightblue"))
```

---

# Effect of becoming president


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-10-1.svg" style="display: block; margin: auto;" /&gt;

---

# Meaning

- Thus far, everything is **topic**-related

--

  - How often he talks about things
  
--

- But what does he **mean** when he talks about Mueller?

--

  - We can probably guess
  
--

- But we want a more systematic method

--

  - **Sentiment**: the *feeling* behind words
  
---

# Meaning

- **Sentiment** analysis is based on **dictionaries**

--

  - Just like **stop words** from last week!
  
--

  - Prepared lists of words, but tagged according to **emotion**
  
--

- Good dictionary included in `tidytext` package


``` r
require(tidytext) # Might need to install.packages('textdata')
```

```
## Loading required package: tidytext
```

``` r
# nrc &lt;- get_sentiments("nrc")
# If this doesn't work on your computer, just load it with read_rds()
nrc &lt;- read_rds('https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/nrc.Rds')
```

---

# Meaning


``` r
nrc
```

```
## # A tibble: 13,901 × 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 abacus      trust    
##  2 abandon     fear     
##  3 abandon     negative 
##  4 abandon     sadness  
##  5 abandoned   anger    
##  6 abandoned   fear     
##  7 abandoned   negative 
##  8 abandoned   sadness  
##  9 abandonment anger    
## 10 abandonment fear     
## # ℹ 13,891 more rows
```

---

# Sentiment by Pre/Post Presidency

- Measure sentiment by proportion of words

--

- Divide by pre/post presidency

--


``` r
word_freq &lt;- tweet_words %&gt;%
  group_by(PostPresident) %&gt;%
  count(word) %&gt;%
  filter(sum(n) &gt;= 5) %&gt;%
   mutate(prop = prop.table(n)) # Faster way of calculating proportions!
```

---

# Sentiment by Pre/Post Presidency

- Attaching sentiment from `nrc`

--

  - `inner_join()`: only keeps words that appear in `nrc`
  

``` r
word_freq_sentiment &lt;- word_freq %&gt;%
    inner_join(nrc, by = "word") 
```

```
## Warning in inner_join(., nrc, by = "word"): Detected an unexpected many-to-many relationship between
## `x` and `y`.
## ℹ Row 7 of `x` matches multiple rows in `y`.
## ℹ Row 2 of `y` matches multiple rows in `x`.
## ℹ If a many-to-many relationship is expected, set
##   `relationship = "many-to-many"` to silence this warning.
```

---

# Sentiment overall


``` r
p &lt;- word_freq_sentiment %&gt;%
  group_by(sentiment) %&gt;%
  top_n(10, n) %&gt;%
  ungroup() %&gt;%
  mutate(word = reorder(word, n)) %&gt;%
  ggplot(aes(y = word, x = n)) +
  facet_wrap(~ sentiment, scales = "free", nrow = 3) + 
  geom_bar(stat = "identity")
```

---

# Sentiment Overall


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;

---

# Sentiment overall

- Could also just calculate positive sentiments - negative sentiments

--

  - Want to do this at the tweet level
  
--


``` r
tweet_sentiment &lt;- tweet_words %&gt;%
    inner_join(nrc, by = "word") 
  
tweet_sentiment_summary &lt;- tweet_sentiment %&gt;%
  group_by(PostPresident, sentiment) %&gt;%
  count(document,sentiment) %&gt;%
  pivot_wider(names_from = sentiment, 
              values_from = n, 
              values_fill = 0) %&gt;% # same as spread()!
  mutate(sentiment = positive - negative)
```

---

# Sentiment overall


``` r
tweet_sentiment_summary
```

```
## # A tibble: 45,592 × 13
## # Groups:   PostPresident [2]
##    PostPresident   document anger anticipation disgust  fear
##    &lt;lgl&gt;              &lt;dbl&gt; &lt;int&gt;        &lt;int&gt;   &lt;int&gt; &lt;int&gt;
##  1 FALSE         1701461182     1            3       1     0
##  2 FALSE         1741160716     1            1       1     0
##  3 FALSE         1924074459     1            1       0     0
##  4 FALSE         2045871770     1            0       0     0
##  5 FALSE         2317112756     1            0       0     1
##  6 FALSE         2346367430     2            1       1     2
##  7 FALSE         2403435685     1            2       1     2
##  8 FALSE         3688564134     1            0       1     1
##  9 FALSE         7677152231     1            1       1     0
## 10 FALSE         8083871612     1            1       1     0
## # ℹ 45,582 more rows
## # ℹ 7 more variables: joy &lt;int&gt;, negative &lt;int&gt;,
## #   positive &lt;int&gt;, sadness &lt;int&gt;, surprise &lt;int&gt;,
## #   trust &lt;int&gt;, sentiment &lt;int&gt;
```

---

# Sentiment by presidency

- Calculate total number of tweets by sentiment

--


``` r
tweet_sentiment_summary  %&gt;%
  group_by(PostPresident) %&gt;%
  mutate(ntweet = 1) %&gt;%
  summarize(across(-document, sum)) 
```

```
## # A tibble: 2 × 13
##   PostPresident anger anticipation disgust  fear   joy
##   &lt;lgl&gt;         &lt;int&gt;        &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1 FALSE          8138        13333    5356  7999 12440
## 2 TRUE          13892        14095    8933 14051 10973
## # ℹ 7 more variables: negative &lt;int&gt;, positive &lt;int&gt;,
## #   sadness &lt;int&gt;, surprise &lt;int&gt;, trust &lt;int&gt;,
## #   sentiment &lt;int&gt;, ntweet &lt;dbl&gt;
```

---

# Sentiment by presidency

- Univariate distributions!

--


``` r
p &lt;- tweet_sentiment_summary %&gt;%
  ggplot(aes(x = sentiment, y = PostPresident)) + 
  geom_boxplot() +
  labs(y= "Trump is president", x = "Sentiment Score: Positive - Negative")
```



---

# Sentiment by presidency

- Univariate distributions!


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-21-1.svg" style="display: block; margin: auto;" /&gt;

---

# Sentiment by hour

- Univariate distributions

  - Comparing sentiment by hour
  
--


``` r
p &lt;- tweet_sentiment %&gt;%
  group_by(PostPresident,Tweeting.hour,sentiment) %&gt;%
  count(document,sentiment) %&gt;%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% 
  mutate(sentiment = positive - negative) %&gt;%
  summarize(AvgSentiment = mean(sentiment)) %&gt;%
  ggplot(aes(y = AvgSentiment, x= Tweeting.hour, color=PostPresident)) + 
  geom_point(size = 4) +
  geom_hline(yintercept = 0,linetype = 'dashed') + 
  labs(x = "Tweeting Hour (EST)", y = "Average Tweet Sentiment: Positive - Negative", color = "Is President?")
```

---

# Sentiment by hour

- Comparing sentiment by hour


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-23-1.svg" style="display: block; margin: auto;" /&gt;


---

# Understanding Trump

- When Trump is coded as "positive" or "negative", what is he saying?

--

- Look at log-odds ratio words, matched to sentiment!


``` r
p &lt;- prepost_logodds %&gt;%
  inner_join(nrc, by = "word") %&gt;%
  filter(!sentiment %in% c("positive", "negative")) %&gt;%
  mutate(sentiment = reorder(sentiment, -logodds),
         word = reorder(word, -logodds)) %&gt;%
  group_by(sentiment) %&gt;%
  top_n(10, abs(logodds)) %&gt;%
  ungroup() %&gt;%
  ggplot(aes(y = word, x = logodds, fill = logodds &lt; 0)) +
  facet_wrap(~ sentiment, scales = "free", nrow = 2) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "", y = "Post / Pre log ratio") +
  scale_fill_manual(name = "", labels = c("Post", "Pre"),
                    values = c("red", "lightblue")) + 
  theme(legend.position = 'bottom')
```

---

# Understanding Trump


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-25-1.svg" style="display: block; margin: auto;" /&gt;

---

# Text as predictors

- Let's say we didn't know when each tweet was written

--

- Could we predict whether it was written during his presidency or not?

--

  - Logit model using **text** as predictors
  
  
---

# Text as Data

- Predict tweets by average of words' log-odds!


``` r
toanal &lt;- tweet_words %&gt;%
  select(document,word,PostPresident) %&gt;%
  left_join(prepost_logodds %&gt;% select(word,logodds)) %&gt;% # Link data with log-odds
  group_by(document,PostPresident) %&gt;%
  summarise(logodds = mean(logodds)) %&gt;% # Calculate average log-odds by document
  ungroup()

m &lt;- glm(PostPresident ~ logodds,toanal,family = binomial) # logit regression
```

---

# Text as Data

- Evaluate the performance


``` r
require(tidymodels)
forAUC &lt;- toanal %&gt;% # Evaluate model performance
  mutate(preds = predict(m,type = 'response'),
         truth = factor(PostPresident,levels = c('TRUE','FALSE')))

roc_auc(forAUC,'truth','preds')
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.962
```

``` r
p &lt;- roc_curve(forAUC,'truth','preds') %&gt;%
  ggplot(aes(x = 1-specificity,y = sensitivity)) + 
  geom_line() + 
  geom_abline(intercept = 0,slope = 1,linetype = 'dashed')
```

---

# Evaluate performance


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-28-1.svg" style="display: block; margin: auto;" /&gt;

---

# Evaluate on some sample tweets


``` r
raw_tweets &lt;- read_rds('https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/Trumptweets.Rds')
set.seed(20)
toCheck &lt;- raw_tweets %&gt;% slice(sample(1:nrow(.),size = 10))

toCheck %&gt;%
  select(content)
```

```
## # A tibble: 10 × 1
##    content                                                  
##    &lt;chr&gt;                                                    
##  1 "RT @ShannonBream: BREAKING:  POTUS commutes Roger Stone…
##  2 "Congratulations to a future STAR of the Republican Part…
##  3 "@Seanelmi  Thanks Sean."                                
##  4 "\"\"\"@007lLisav: @CNN @realDonaldTrump @CNNPolitics ca…
##  5 "RT @thejtlewis: @realDonaldTrump https://t.co/W7L9kCZK3…
##  6 "RT @TrumpWarRoom: WATCH: @KatrinaPierson explains Joe B…
##  7 "The State Department's 'shadow government' #DrainTheSwa…
##  8 "Sexual pervert Anthony Weiner has zero business holding…
##  9 "TO MY FAVORITE PEOPLE IN THE WORLD! https://t.co/38DbQt…
## 10 "Small businesses will have an ally in the White House w…
```

---

# Evaluate on some sample tweets


``` r
toTest &lt;- toCheck %&gt;% left_join(toanal,by = c('id' = 'document')) # Merge the raw text with the log-odds

toTest %&gt;%
  mutate(preds = predict(m,newdata = toTest,type = 'response')) %&gt;%
  select(content,PostPresident,preds) %&gt;%
  mutate(pred_binary = preds &gt; .5) %&gt;%
  filter(PostPresident != pred_binary)
```

```
## # A tibble: 3 × 4
##   content                    PostPresident preds pred_binary
##   &lt;chr&gt;                      &lt;lgl&gt;         &lt;dbl&gt; &lt;lgl&gt;      
## 1 @Seanelmi  Thanks Sean.    FALSE         0.985 TRUE       
## 2 The State Department's 's… FALSE         0.731 TRUE       
## 3 TO MY FAVORITE PEOPLE IN … TRUE          0.316 FALSE
```

``` r
# We only make 3 mistakes!
```


---

# Can we do better if we add sentiment?


``` r
toanal &lt;- toanal %&gt;%
  left_join(tweet_sentiment_summary) %&gt;%
  drop_na()
```

```
## Joining with `by = join_by(document, PostPresident)`
```

``` r
m1 &lt;- glm(PostPresident ~ logodds,toanal,family = binomial)
m2 &lt;- glm(PostPresident ~ logodds + sentiment,toanal,family = binomial)
m3 &lt;- glm(PostPresident ~ logodds + anger + anticipation + disgust + fear + joy + sadness + surprise + trust,toanal,family = binomial)

forAUC &lt;- toanal %&gt;%
  mutate(preds1 = predict(m1,type = 'response'),
         preds2 = predict(m2,type = 'response'),
         preds3 = predict(m3,type = 'response'),
         truth = factor(PostPresident,levels = c('TRUE','FALSE')))
```

---

# Can we do better if we add sentiment?


``` r
roc_auc(forAUC,'truth','preds1') %&gt;% mutate(model = 'logodds') %&gt;%
  bind_rows(roc_auc(forAUC,'truth','preds2') %&gt;% mutate(model = 'logodds &amp; net sentiment')) %&gt;%
  bind_rows(roc_auc(forAUC,'truth','preds3') %&gt;% mutate(model = 'logodds &amp; detailed sentiment'))
```

```
## # A tibble: 3 × 4
##   .metric .estimator .estimate model                       
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                       
## 1 roc_auc binary         0.966 logodds                     
## 2 roc_auc binary         0.967 logodds &amp; net sentiment     
## 3 roc_auc binary         0.968 logodds &amp; detailed sentiment
```

--

- Not really

---

# Conclusion

- Sentiment can...

--

  - ...help us describe the data (i.e., infer what someone meant)
  
  - ...help us predict the data (RQ: do positive tweets get more likes?)

---

# BREAK

---

# Final fun things: maps!

- Install `maps`


``` r
require(tidyverse)
require(maps)
require(mapproj)

# Load dataset included in maps package
states48 &lt;- map_data('state')

states48 %&gt;%
  as_tibble()
```

```
## # A tibble: 15,537 × 6
##     long   lat group order region  subregion
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;    
##  1 -87.5  30.4     1     1 alabama &lt;NA&gt;     
##  2 -87.5  30.4     1     2 alabama &lt;NA&gt;     
##  3 -87.5  30.4     1     3 alabama &lt;NA&gt;     
##  4 -87.5  30.3     1     4 alabama &lt;NA&gt;     
##  5 -87.6  30.3     1     5 alabama &lt;NA&gt;     
##  6 -87.6  30.3     1     6 alabama &lt;NA&gt;     
##  7 -87.6  30.3     1     7 alabama &lt;NA&gt;     
##  8 -87.6  30.3     1     8 alabama &lt;NA&gt;     
##  9 -87.7  30.3     1     9 alabama &lt;NA&gt;     
## 10 -87.8  30.3     1    10 alabama &lt;NA&gt;     
## # ℹ 15,527 more rows
```

---

# Maps

- `maps` data are prepared to run with `ggplot()`

--

  - Specifically, want to use `geom_polygon()`
  
--


``` r
p &lt;- states48 %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group),
               color = 'black',
               fill = 'lightblue')
```

---

# Maps


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-35-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Can quickly improve with pre-made `theme()`s and `coord()`s

--


``` r
p + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-36-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Can zoom in with `filter()`

--


``` r
ny &lt;- states48 %&gt;%
  filter(region == 'new york')

pNY &lt;- ny %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group),
               color = 'black',
               fill = 'grey85') + 
  theme_void()
```

---

# Maps


``` r
pNY
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-38-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps


``` r
pNY + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-39-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Can also get counties prepared!


``` r
counties &lt;- map_data('county')

pCty &lt;- counties %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group),
               color = 'black',
               fill = 'grey90') + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
pCty
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-41-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps


``` r
pNYCty &lt;- counties %&gt;%
  filter(region == 'new york') %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group),
               color = 'black',
               fill = 'grey90') + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
pNYCty
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-43-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Want to visualize data!

--

- Put the `fill` inside the `aes`

--

- But we need data first

--


``` r
JBStates &lt;- c('new york','california','vermont','massachusetts','district of columbia','tennessee','connecticut')

states48 &lt;- states48 %&gt;%
  mutate(jbLived = ifelse(region %in% JBStates,'Lived','Never lived'))
```

---

# Maps


``` r
p &lt;- states48 %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group,fill = jbLived),
               color = 'black',alpha = .6) + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
p + 
  scale_fill_manual(name = '',values = c('Lived' = 'darkgreen','Never lived' = 'grey95')) + 
  labs(title = "Places I've Lived in the U.S.")
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-46-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Also have world maps!


``` r
JBCountries &lt;- c('USA','South Korea','France','UK',
                 'Germany','Switzerland','Greece',
                 'Dominican Republic','Saint Lucia',
                 'China','Thailand','Cambodia','Japan',
                 'Guatemala','Aruba','Canada','Belize','Mexico')
world &lt;- map_data('world')

world &lt;- world %&gt;%
  mutate(jbVisit = ifelse(region %in% JBCountries,'Visited','Never been'))

p &lt;- world %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group,fill = jbVisit),
               color = 'black',alpha = .6) + 
  theme_void()
```

---

# Maps


``` r
p + 
  scale_fill_manual(name = '',values = c('Visited' = 'darkgreen','Never been' = 'grey95')) + 
  labs(title = "Places I've Visited")
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-48-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- More interesting data?

--


``` r
PollDat &lt;- readRDS('../data/PresStatePolls04to20.Rds') %&gt;%
  as_tibble() %&gt;%
  rename(region = state.name)

PollDat %&gt;% head()
```

```
## # A tibble: 6 × 11
##   state.postal  year samplesize dem.poll rep.poll dem.vote
##   &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 AK            2016        500     30       38       37.7
## 2 AK            2016        201     37.4     37.7     37.7
## 3 AK            2016        660     30.6     36.1     37.7
## 4 AK            2008        500     42       53       37.9
## 5 AK            2008        500     41       57       37.9
## 6 AK            2016        409     31       48       37.7
## # ℹ 5 more variables: rep.vote &lt;dbl&gt;,
## #   days.until.election &lt;dbl&gt;, days.in.field &lt;dbl&gt;,
## #   EV &lt;int&gt;, region &lt;chr&gt;
```

---

# Maps

- Collapse to state-by-year

--


``` r
PollDat &lt;- PollDat %&gt;%
  group_by(year,region) %&gt;%
  summarise(DemPct = mean(dem.poll,na.rm=T),
            RepPct = mean(rep.poll,na.rm=T),
            DemVote = first(dem.vote),
            RepVote = first(rep.vote)) %&gt;%
  ungroup()
```

```
## `summarise()` has grouped output by 'year'. You can
## override using the `.groups` argument.
```

---

# Maps

- Merge with map data

--


``` r
toplot &lt;- states48 %&gt;%
  left_join(PollDat %&gt;%
              filter(year == 2020))
```

```
## Joining with `by = join_by(region)`
```

``` r
p &lt;- toplot %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group,fill = DemPct),
               color = 'black') + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-52-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Let's adjust with `scale_fill_continuous()`


``` r
p + 
  scale_fill_continuous(name = 'Biden %',low = 'red',high = 'blue')
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-53-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Could also `cut` to create bins


``` r
p + 
  scale_fill_stepsn(colors = c('darkred','red','tomato','grey80','skyblue','blue','darkblue'),
                    breaks = c(30,35,40,49,51,60,65,70))
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-54-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Different geographies &amp; different data


``` r
countycovid &lt;- readRDS('../data/countycovid.Rds') # Already prepared!

p &lt;- countycovid %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group,fill = deaths),
               color = 'grey90') + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
p + 
  scale_fill_continuous(name = 'Deaths',low = 'white',high = 'red')
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-56-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Raw deaths are a bad measure...why?

--

- Want to normalize by population!


``` r
p &lt;- countycovid %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group,
                   fill = deaths*100000/population)) + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
p + 
  scale_fill_continuous(name = 'Deaths (per 100K)',
                        low = 'white',high = 'red')
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-58-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- What about more precise things?

--

- I.e., where I've lived by county


``` r
jbCounties &lt;- c('norfolk:massachusetts','washington:vermont',
                'manhattan:new york','san francisco:california',
                'davidson:tennessee','hartford:connecticut',
                'washington:district of columbia')

counties &lt;- counties %&gt;%
  mutate(combReg = paste0(subregion,":",region)) %&gt;%
  mutate(jbLived = ifelse(combReg %in% jbCounties,'Lived',
                          'Never lived'))

p &lt;- counties %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group,
                   fill = jbLived)) + 
  theme_void() + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-60-1.svg" style="display: block; margin: auto;" /&gt;

---

# Maps

- Can add points instead!

--


``` r
jbLivedDF &lt;- data.frame(combReg = jbCounties,
                        years = c(18,18,7,1,.4,3,4))

counties &lt;- counties %&gt;% left_join(jbLivedDF)

p &lt;- counties %&gt;%
  ggplot() + 
  geom_polygon(aes(x = long,y = lat,group = group),
               fill = 'grey95',color = 'grey70') + 
  geom_point(data = counties %&gt;%
               drop_na(years) %&gt;%
               group_by(group,years) %&gt;%
               summarise(long = mean(long),lat = mean(lat)),
             aes(x = long,y = lat,size = years),shape = 21,color = 'red') + 
  theme_void() + 
  scale_size_continuous(range = c(2,10),breaks = c(1,5,10)) + 
  coord_map('albers',lat0 = 30,lat1 = 40)
```

---

# Maps


``` r
p
```

&lt;img src="ISP_lecture_12_slides_files/figure-html/unnamed-chunk-62-1.svg" style="display: block; margin: auto;" /&gt;


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
