---
title: "Intro to `R`"
subtitle: "Functions, Objects and Visualization"
author: "Prof. Bisbee"
institute: "Seoul National University"
date: "Slides Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    # self_contained: true
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    css:
      - default
      - css/lexis.css
      - css/lexis-fonts.css
    #seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
      #ratio: "16:9"

---

```{css,echo = F}
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
```

```{r,include=F}
set.seed(20230906)
options(width=60)
knitr::opts_chunk$set(fig.align='center',fig.width=9,fig.height=5,dev = 'svg')
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

# Agenda

1. Recap of last lecture

--

  - Using packages: `install.packages()` & `require()`
  
  - Loading and manipulating data: `read_rds()` and `%>%`
  
--

2. `tidyverse` functions

--

  - `filter` and `select`
  
  - `summarize` and `mutate`
  
  - `group_by`

---

# Loading Packages & Data

--

- Create an `.Rmd` file and save to your `code` folder

--

  - Accept defaults, Save As... (with a good name), then `knit`

--

- Load the `tidyverse` package

```{r,message=F,warning=F}
require(tidyverse)
```

--

- Load the data from the course [github page](https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/sc_debt.Rds) directly using `read_rds()`

--

  - We **create** an "object" to store the data using a left-arrow: `<-`

--

```{r}
df<-read_rds("https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/sc_debt.Rds") 
```

---

# Tabular Data

- Data comes in many different formats

--

- **Structured data**: standardized, well-defined structure, easily accessed

  - I.e., tables, databases
  
  - In my YouTube example, the survey we gave was **structured**
  
--
  
- **Unstructured data**: messy, organic, disorganized, hard to use

  - I.e., web pages, images, videos
  
  - In my YouTube example, the scraped HTML code of a list of recommendations was **unstructured**
  
--

- In this class, we will always be working with **structured** data...specifically "tabular data frames"

--

- This still requires work to prepare!

---

# Tabular Data Frame

- AKA a "tibble"

--

- These are "square" (although actually rectagular)

--

- Rows: **units of observation** (i.e., the entities we are studying)

--

  - People (each row is a survey respondent, athlete, etc.)
  
  - Places (each row is a state, county, country, etc.)
  
  - Things (each row is a tweet, firm, product, etc.)
  
--

- Columns: **variables of interest** (i.e., attributes we are studying)

--

  - Beliefs / behaviors / etc. (i.e., where rows are people)
  
  - Rainfall / crimes / etc. (i.e., where rows are places)
  
  - Likes / profits / etc. (i.e., where rows are things)
  
---

# Looking at Data

--

- We now have the contents of `sc_debt.Rds` stored in the object `df`

--

- We can look at this object directly

```{r}
df
```

---

# Looking at Data

- What is our **unit of observation**?

--

  - Academic institutions: each row is a single school

--

- What are our **variables of interest**?

--

  - Let's look!
  
```{r}
colnames(df) # Prints the variable names
```

---

# Good Data has Codebooks!

```{r,echo=FALSE,message=FALSE}
defs <- data.frame(Name = names(df),
                   Definition = c('Unit ID','Institution Name','State Abbreviation','Median Debt of Graduates',
                            'Control Public or Private','Census Region','Predominant Degree Offered: Assocates or Bachelors',
                            'Open Admissions Policy: 1=Yes, 2=No, 3=No 1st time students',
                            'Admissions Rate: proportion of applications accepted','Type of institution*',
                            'Average SAT scores',
                            'Average Earnings of Recent Graduates',
                            'Number of undergraduates',
                            'Average cost of attendance (tuition-grants)',
                            'Institution admits fewer than 10% of applications, 1=Yes, 0=No',
                            'Institution is a research university, 1=Yes, 0=No'))
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
require(kableExtra)
defs %>%
  kbl() %>%
  kable_paper("hover", full_width = F,font_size = 13)
```
&ast;<font size="2">See [here](https://data.ed.gov/dataset/9dc70e6b-8426-4d71-b9d5-70ce6094a3f4/resource/658b5b83-ac9f-4e41-913e-9ba9411d7967/download/collegescorecarddatadictionary_01192021.xlsx)</font>

---

# Looking at data

- Looking at data is **crucial**

```{r}
# First 6 rows
df %>% head()
```

- (Same as `head(df)`)

---

# Looking at data

- Looking at data is **crucial**

```{r}
# Last 6 rows
df %>% tail()
```

- (Same as `tail(df)`)


---

# Manipulating the Data

- Last lecture, we wanted to know...

--

  1. Where is `Vanderbilt University`?
  
```{r}
df %>%
  filter(instnm == "Vanderbilt University") # Only select rows with Vandy
```

---

# Manipulating the Data

- What if we don't know precisely how Vandy is spelled in these data?

--

- `str_detect()` and `grepl()` to the rescue!

```{r}
df %>%
  filter(str_detect(instnm,'Vand'))
```

---

# Manipulating the Data

- What if we don't know precisely how Vandy is spelled in these data?

- `str_detect()` and `grepl()` to the rescue!

```{r}
df %>%
  filter(grepl('Vand',instnm))
```

---

# Manipulating the Data

- We can go deeper with this logic

  - "or" denoted with `|`
  
  - "and" denoted with `&`

--

```{r}
df %>%
  filter(str_detect(instnm,"Vand") | str_detect(instnm,"Tenn"))
```

---

# Manipulating the Data

- We can go deeper with this logic

  - "or" denoted with `|`
  
  - "and" denoted with `&`

--

```{r}
df %>%
  filter(str_detect(instnm,"Vand") & str_detect(instnm,"Univ"))
```

---

# Manipulating the Data

- Can also put `|` or `&` in a single `str_detect()`

```{r}
df %>%
  filter(str_detect(instnm,'Vand|Tenn'))
```

---

# Manipulating the Data

- But **can't** do the same with `&`

```{r}
df %>%
  filter(str_detect(instnm,'Vand&Univ'))
```

---

# Manipulating the Data

- Negations are handled with `!`

--

  - Literally means "not"
  
--

- Drop rows with "of" in the school name

```{r}
df %>%
  filter(!str_detect(instnm,"of"))
```

---

# Manipulating the Data

- (same as...)

```{r}
df %>%
  filter(!grepl("of",instnm))
```


---

# Manipulating: `select()`

- Still TMI!

--

- Before, I only cared about the admissions rate (`adm_rate`), the SAT scores (`sat_avg`), and the future earnings (`md_earn_wne_p6`)

--

- `select` will select **columns**

```{r}
df %>%
  filter(instnm == "Vanderbilt University") %>%
  select(instnm,adm_rate,sat_avg,md_earn_wne_p6) # Select variables of interest
```

---

# Manipulating: `select()`

- We can use `matches()` function with `select()` in a manner similar to `str_detect()`

```{r}
df %>%
  select(matches("_"))
```


---

# Stepping back

- .blue[RQ]: How might admissions and SAT scores be **related**?

--

  - .blue[Theory]: selective schools have stricter criteria
  
--

  - .blue[Hypothesis]: admissions and SAT scores should be **negatively** related
  
--

- How can we test this hypothesis?


---

# Summarizing Data: `summarise()` + `mean()`

--

- We can combine base `R` functions with `tidyverse` functions!

--

  - Base `R`: `mean()`
  
  - `tidyverse`: `summarise()` (aka `summarize()`)
  
- Overall average SAT scores

```{r}
df %>%
  summarise(mean_sat = mean(sat_avg,na.rm=T)) # Average SAT scores for entire data
```

---

# Summarizing Data

- Let's unpack this

```{r,eval=F}
df %>%
  summarise(mean_sat = mean(sat_avg,na.rm=T))
```

--

  - Create new variable `mean_sat` that contains the `mean()` of every school's average SAT score
  
--

  - `na.rm=T` means we want to ignore missing data. If not?
  
--
  
```{r,eval=T}
df %>%
  summarise(mean_sat = mean(sat_avg))
```

---

# Summarizing Data

--

- Recall we want see if more selective schools have higher SAT scores

--

```{r,eval=T}
df %>%
  filter(adm_rate < .1) %>% # Only schools who accept < 10%
  summarise(mean_sat_LT10 = mean(sat_avg,na.rm=T)) # Average SAT
```

```{r,eval=T}
df %>%
  filter(adm_rate > .1) %>% # Only schools who accept > 10%
  summarise(mean_sat_GT20 = mean(sat_avg,na.rm=T)) # Average SAT
```

---

# Adding / changing variables: `mutate()`

--

- `mutate()` creates a new variable

--

```{r}
df %>%
  mutate(newvar = 1) %>%
  select(instnm,newvar)
```

---

# Object Assignment Operator: `<-`

- Thus far, nothing we have done has changed `df`

--

- Use object assignment operator `<-` to **overwrite** an existing object

--

```{r}
df <- df %>%
  mutate(adm_rate_pct = adm_rate*100)
```

--

- Did it work?

```{r}
df %>%
  summarise(adm_rate_pct = mean(adm_rate_pct,na.rm=T),
            adm_rate = mean(adm_rate,na.rm=T))
```

---

# Logic: `ifelse()`

- 3 inputs:

  - Logical statement (labeled `test`)
  
  - Value if the logic is `TRUE` (labeled `yes`)
  
  - Value if the logic is `FALSE` (labeled `no`)
  
--

- `ifelse([LOGIC],[VALUE IF TRUE],[VALUE IF FALSE])`

---

# Logic: `ifelse()`

- Say it out loud: "Create a new variable called `sel` that records if the school is selective or not. If the admissions rate is less than 10% (0.1), record the school as `sel = 1`. Otherwise, record the school as `sel = 0`."

```{r,eval = F}
df %>%
  mutate(sel = ifelse(test = [LOGIC],
                      yes = [VALUE IF TRUE],
                      no = [VALUE IF FALSE]))
```
---

# Logic: `ifelse()`

- Say it out loud: "Create a new variable called `sel` that records if the school is selective or not. **If the admissions rate is less than 10% (0.1)**, record the school as `sel = 1`. Otherwise, record the school as `sel = 0`."

```{r,eval = F}
df %>%
  mutate(sel = ifelse(test = `adm_rate < 0.1`, # This is the logic
                      yes = [VALUE IF TRUE],
                      no = [VALUE IF FALSE]))
```

---

# Logic: `ifelse()`

- Say it out loud: "Create a new variable called `sel` that records if the school is selective or not. If the admissions rate is less than 10% (0.1), **record the school as `sel = 1`**. Otherwise, record the school as `sel = 0`."

```{r,eval = F}
df %>%
  mutate(sel = ifelse(test = adm_rate < 0.1, # This is the logic
                      yes = `1`, # This is the value if TRUE
                      no = [VALUE IF FALSE]))
```
---

# Logic: `ifelse()`

- Say it out loud: "Create a new variable called `sel` that records if the school is selective or not. If the admissions rate is less than 10% (0.1), record the school as `sel = 1`. **Otherwise, record the school as `sel = 0`**."

```{r,eval = F}
df %>%
  mutate(sel = ifelse(test = adm_rate < 0.1, # This is the logic
                      yes = 1, # This is the value if TRUE
                      no = `0`)) # This is the value if FALSE
```
---

# Logic: `ifelse()` + `mutate()`

- Remember that if we want to keep this, we need the **assignment operator** `<-`

```{r}
df <- df %>%
  mutate(sel = ifelse(test = adm_rate < 0.1, # This is the logic
                      yes = 1, # This is the value if TRUE
                      no = 0)) # This is the value if FALSE
```


---

# Summarizing Data: `group_by()`

--

- One final `tidyverse` function: `group_by()`

--

- Let's use the newly created `selective` variable which is either 1 or 0

--

```{r}
df %>%
  select(instnm,selective,adm_rate)
```

---

# Summarizing Data: `group_by()`

- Instead of running two separate `filter()` commands, use `group_by()`

--

```{r,eval=T}
df %>%
  # Group the data by selective (either 1 or 0)
  group_by(selective) %>% 
  # Calculate average SAT for each group
  summarise(mean_sat = mean(sat_avg,na.rm=T)) 
```

---

# Results

- Do more selective schools have higher SAT scores?

--

- Yes

--

- This .red[Result] **confirms** our .blue[Hypothesis] and **answers** our .blue[Research Question]

---

# Conclusion

--

- What we've done today is a microcosm of data science

--

  1. Opened .red[data] (`readRDS`)
  
--
  
  2. Looked at .red[data] (`tidyverse` + `select()`, `filter()`, `arrange()`)
    
--

  3. Generated .blue[hypotheses] (Admissions versus SAT scores)
  
--

  4. .red[Tested] .blue[hypotheses] (`summarise()` + `mean()`)

---

name: advanced

# Advanced Logic: `filter()`

[If no time, jump to end](#end)

- `filter()` command with other logical operators

--
  - `>, <`: greater than, less than (`>=, <=`)
  - `!`: not (i.e., `!=` means "not equal to")
  - `&`: and
  - `|`: or
  
--

```{r}
df %>%
  # Schools EXCEPT Vandy
  filter(instnm != "Vanderbilt University") %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `str_detect()`

- `filter()` command with other functions

--

  - `str_detect([VAR],[PATTERN])`: detect a string
  - `grepl([PATTERN],[VAR])`: also detects a string

--

```{r}
df %>%
  filter(str_detect(instnm,"Vanderbilt")) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `str_detect()`

- String detection is case sensitive!

--

```{r}
df %>%
  filter(str_detect(instnm,"VAND")) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

--

```{r}
df %>%
  filter(str_detect(instnm,"anderbil")) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `&` (and), `|` (or)

```{r}
df %>%
  filter(str_detect(instnm,"Colorado")) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `&` (and), `|` (or)

```{r}
df %>%
  filter(grepl("Colorado",instnm) & grepl(' of ',instnm)) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `&` (and), `|` (or)

```{r}
df %>%
  filter(grepl("Colorado",instnm) | grepl('Vermont',instnm)) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `&` (and), `|` (or)

```{r}
df %>%
  filter((grepl("Colorado",instnm) | grepl('Vermont',instnm)) & grepl(' of ',instnm)) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `&` (and), `|` (or)

- `&` can be separated into multiple `filter()` commands

```{r}
df %>%
  filter((grepl("Colorado",instnm) | grepl('Vermont',instnm))) %>%
  filter(grepl(' of ',instnm)) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Advanced Logic: `&` (and), `|` (or)

- `|` can be moved into the `str_detect()` or `grepl()` commands

```{r}
df %>%
  filter(grepl("Colorado|Vermont",instnm)) %>%
  filter(grepl(' of ',instnm)) %>%
  select(instnm,stabbr,adm_rate,sat_avg)
```

---

# Quick Test

- Filter schools from Texas with the word "community" in their name

```{r}
# INSERT CODE HERE
```

---

# Advanced Logic: `select()`

- `select` can be paired with `matches()` or `contains()` for similar flexibility (equivalent to `str_detect()` or `grepl()` for `filter()`)

--

```{r}
df %>%
  select(contains('inst'))
```

---

# Advanced Logic: `select()`

- `matches` can work with `|`

```{r}
df %>%
  select(!matches('_|inst'))
```

---

# Advanced Logic: `select()`

- `select` can also work with `where` to find classes

```{r}
df %>%
  select(where(is.numeric))
```

---

# Quick Test

- Filter to only schools in California and select only character columns

```{r}
# INSERT CODE HERE
```


---

name: end

# BREAK

---

---

# The Two Camps

<center><img src="figs/camps3.png" width="80%"></center>


---

# The .blue[Research] Camp

- .blue[RQ]: How might admissions and SAT scores be **related**?

--

  - .blue[Theory]: selective schools have stricter criteria
  
--

  - .blue[Hypothesis]: admissions and SAT scores should be **negatively** related
  
--

- How can we test this hypothesis?

---

# Previously: `summarise()`

--

- We can combine base `R` functions with `tidyverse` functions!

--

  - Base `R`: `mean()`
  
  - `tidyverse`: `summarise()` (aka `summarize()`)
  
--
  
- Overall average SAT scores

```{r}
df %>%
  summarise(mean_sat = mean(sat_avg,na.rm=T))
```

---

# Previously: `summarise()`

--

- Let's unpack this

```{r,eval=F}
df %>%
  summarise(mean_sat = mean(sat_avg,na.rm=T))
```

--

  - Create new variable `mean_sat` that contains the `mean()` of every school's average SAT score
  
--

  - `na.rm=T` means we want to ignore missing data. If not?
  
--
  
```{r,eval=T}
df %>%
  summarise(mean_sat = mean(sat_avg))
```

---

#`summarise()` + `filter()`

--

- Recall we want see if more selective schools have higher SAT scores

--

```{r,eval=T}
df %>%
  filter(adm_rate < .1) %>%
  summarise(mean_sat_LT10 = mean(sat_avg,na.rm=T))
```

```{r,eval=T}
df %>%
  filter(adm_rate > .1 & adm_rate < .2) %>%
  summarise(mean_sat_1020 = mean(sat_avg,na.rm=T))
```

---

# `summarise()` + `group_by()`

--

- One final `tidyverse` function: `group_by()`

--

```{r,eval=T}
df %>%
  group_by(selective) %>%
  summarise(mean_sat = mean(sat_avg,na.rm=T))
```


---

# Plotting data

--

- Let's plot the data instead of writing many of these `summarise()` functions

--

- Visualization in `R` uses `ggplot()` function

--

  - Inputs: `aes(x,y,...)` (elipses `...` indicates many more inputs)
  
  - `x` is the x-axis (horizontal)
  
  - `y` is the y-axis (vertical)
  

---

# `ggplot()`

- Attach `ggplot()` to your data with `%>%`

```{r}
df %>% #<<
  ggplot()
```

---

# `ggplot()`

- Then tell it what to put in the x-axis and y-axis

--

- What should go on these axes?

--

- .blue[Theory]: Selective schools choose higher scoring students

--

  - Selective schools **explain** higher scores
  
  - Selective schools: **independent variable** / **explanatory variable** / **predictor** / $X$
  
  - Higher scores: **dependent variable** / **outcome variable** / $Y$
  
--

- Selective schools go on the x-axis, SAT scores go on the y-axis

---

# `ggplot()`

```{r}
df %>%
  ggplot(aes(x = adm_rate,y = sat_avg)) #<<
```

---

# `ggplot()`

- This gives us an empty plot

--

- We have the correct variables on the correct axes...

--

- ...but we need to choose how to display them

--

- There are many different `ggplot()` functions to choose from

--

  - `geom_point()` creates one point for each x and y coordinate
  
  - `geom_bar()` creates a barplot
  
  - `geom_histogram()` creates a histogram
  
  - `geom_density()` creates a density plot
  
  - `geom_boxplot()` creates a box-and-whisker plot
  
---

# `ggplot()`

- We **add** a second `ggplot()` function to the first with a plus sign `+`

--

  - **NB:** This is JUST LIKE THE PIPE OPERATOR `%>%` in `tidyverse`!
  
--

- Since `adm_rate` (the x-axis variable) and `sat_avg` (the y-axis variable) are both numeric ("continuous") measures, we will use `geom_point()`

--

  - We will come back to **variable types** and how to visualize them later
  
---

# `ggplot()`

```{r,warning=F}
df %>%
  ggplot(aes(x = adm_rate,y = sat_avg)) + 
  geom_point() #<<
```

---

# Plotting data

--

- Let's unpack this

--

  - `aes(x,y)` sets the basic aesthetics for the plot
  
--

  - `geom_point()` tells `ggplot()` how to visualize those aesthetics
  
--

  - These two parts are linked with the `+`. Similar to...?

--

  - ...the `%>%` in `tidyverse`!

---

# Interpreting the plot

--

- We **hypothesized** that admissions and SAT scores are negatively related

--

  - Is this supported in the data?
  
--

- Let's add a line of best fit with `geom_smooth()`

```{r,eval = F}
df %>%
  ggplot(aes(x = adm_rate,y = sat_avg)) + 
  geom_point() + 
  geom_smooth(method = 'lm',se = F) #<<
```

---

```{r,echo=F,warning=F,message = F}
df %>%
  ggplot(aes(x = adm_rate,y = sat_avg)) + 
  geom_point() + 
  geom_smooth(method = 'lm',se = F)
```


---

# The .blue[Research] Camp

- .blue[RQ]: How might future earnings and SAT scores be **related**?

--

  - .blue[Theory]: SATs measure student ability.
  
  - .blue[Theory]: Student ability is valued by the labor market.
  
  - .blue[Theory]: Firms pay more for students with higher SAT scores.
  
--

  - .blue[Hypothesis]: Earnings and SAT scores should be **positively** related
  
---

# Plotting Quiz

- Which variable goes on the x-axis?

--

  - **SAT scores**
  
--

- Which variable goes on the y-axis?

  - **Earnings**
  
--

- In our theory, SAT scores **cause** earnings

--

- Why might this **not** be the case?

--

  - Spurious 1: SAT scores **and** earnings are caused by student ability
  
  - Spurious 2: SAT scores **and** earnings are caused by socio-economic privilege
  
---

# Let's Plot!

```{r,eval = F}
df %>%
  ggplot(aes(x = sat_avg,y = md_earn_wne_p6)) + # Build axes
  geom_point() +  # Add points
  geom_smooth(method = 'lm',se = F) # Add line of best fit
```

---

# Outliers

- Which schools are furthest from the line?

--

  - These are **outliers**
  
--

  - These schools are the **furthest** from our .blue[theory]

--

```{r}
df %>%
  mutate(out = ifelse(md_earn_wne_p6 > 100000,
                          instnm,  # Value if TRUE
                          NA)) %>% # Value if FALSE
  drop_na(out,sat_avg) %>%
  select(instnm,md_earn_wne_p6,sat_avg)
```

---

# Plotting data

- We can add these as labels!

```{r,eval=F}
df %>%
   mutate(out = ifelse(md_earn_wne_p6 > 100000,
                          instnm,  # Value if TRUE
                          NA)) %>% # Value if FALSE
  ggplot(aes(x = sat_avg,y = md_earn_wne_p6,
             label = out)) + #<<
  geom_point() + 
  geom_text() #<<
```

---

# Plotting data

```{r,echo=F,warning=F}
df %>%
   mutate(out = ifelse(md_earn_wne_p6 > 100000,instnm,NA)) %>%
  ggplot(aes(x = sat_avg,y = md_earn_wne_p6,label = out)) + 
  geom_point() + geom_text()
```

---

# Plotting data

- Let's accentuate the outlier more with color

```{r}
p <- df %>%
   mutate(out = ifelse(md_earn_wne_p6 > 100000,
                          instnm,  # Value if TRUE
                          NA)) %>% # Value if FALSE
  drop_na(sat_avg) %>%
  ggplot(aes(x = sat_avg,y = md_earn_wne_p6,
             label = out,color = out)) + #<<
  geom_point() + 
  scale_color_manual(name = "Outlier",values = c('red','red','black')) + #<<
  geom_text(hjust = .5,vjust = 1,color = 'black',size = 3)
```

---

# Plotting data

```{r,echo=F,warning=F}
p + 
  theme(legend.position = 'none')
```



---

# Categorical Data

- Thus far, plotting two continuous variables with `geom_point()`

--

- What if we wanted to see which state has the most selective schools?

--

- Use `group_by()` and `summarise()`
  
--

```{r}
df %>%
  group_by(stabbr) %>%
  summarise(selective_avg = mean(adm_rate,na.rm=T))
```

---

# Categorical Data

- Two variables (`stabbr` and `selective_avg`), but one of them is now a `character` type

--

- Can we plot this as a scatterplot?

--

```{r}
p <- df %>%
  group_by(stabbr) %>%
  summarise(selective_avg = mean(adm_rate,na.rm=T)) %>%
  ggplot(aes(x = stabbr,y = selective_avg)) + 
  geom_point()
```

---

# Categorical Data

- Yes...but it isn't very pretty

```{r}
p
```

---

# Categorical Data: `geom_bar()`

- NB: `geom_bar()` will automatically count the values on the x-axis
  
--

```{r}
df %>%
  ggplot(aes(x = stabbr)) + 
  geom_bar()
```

---

# Categorical Data: `geom_bar()`

- This is fine if we just want to know which states have the most schools in our data

--

- But we want to put the average admissions rate on the y-axis instead

--

  - Need to **override** `geom_bar()` default behavior
  
```{r}
p <- df %>%
  group_by(stabbr) %>%
  summarise(selective_avg = mean(adm_rate,na.rm=T)) %>%
  ggplot(aes(x = stabbr,y = selective_avg)) + 
  geom_bar(stat = 'identity') #<<
```

---

# Categorical Data

```{r}
p
```

---

# Categorical Data

- Getting a little better, but still ugly

--

- Use `reorder()` to sort the x-axis values by the y-axis

```{r}
p <- df %>%
  group_by(stabbr) %>%
  summarise(selective_avg = mean(adm_rate,na.rm=T)) %>%
  ggplot(aes(x = reorder(stabbr,selective_avg),y = selective_avg)) + #<<
  geom_bar(stat = 'identity')
```

---

# Categorical Data

- Even better!

```{r}
p
```

---

# Plot Tweaking

- We could go even further and swap the x and y-axes (although this isn't always a good idea!)

```{r}
p <- df %>%
  group_by(stabbr) %>%
  summarise(selective_avg = mean(adm_rate,na.rm=T)) %>%
  ggplot(aes(y = reorder(stabbr,selective_avg),x = selective_avg)) + #<<
  geom_bar(stat = 'identity')
```

---

# Plot Tweaking

```{r}
p
```

--

- Still ugly though! We want to tweak the labels with `labs()`

---

# Plot Tweaking

```{r}
p + 
  labs(title = "Average Admissions by State",
       x = "Admissions Rate",
       y = "State")
```

---

# Conclusion

--

- What to take away

--

  1. Which variables go on which axes
  
  2. How to put these on a `ggplot()` figure
  
  3. How to create a visualization of these variables
  
--

- This wraps up the crash course in `R`

--

  - **REMEMBER**: This class is *inherently* challenging because of `R`
  
--

  - The course is graded leniently to reflect the inherent difficulty of the material
