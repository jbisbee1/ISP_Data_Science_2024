---
title: "Clustering"
subtitle: "Part 1"
author: "Prof. Bisbee"
institute: "Seoul National University"
date: "Slides Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    # self_contained: true
    chakra: libs/remark-latest.min.js
    lib_dir: libs
    css:
      - default
      - css/lexis.css
      - css/lexis-fonts.css
    #seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      #ratio: "16:9"

---

```{css,echo = F}
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
```

```{r,include=F}
options(width=60)
knitr::opts_chunk$set(fig.align='center',fig.width=9,fig.height=5,dev = 'svg')
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

# Agenda

1. Structure in data

2. "Clustering"

3. Application

---

# Structure

--

- Patterns in data

--

- Behind everything we've done thus far

--

  - .blue[Theory Testing:] structure answers research question
  
  - .blue[Prediction:] structure improves accuracy
  
--

- A third "camp" in data science: **Learning**

---

# Learning

--

- No research question, no prediction goal

--

  - Just want to learn about **structure** of data
  
--

- Existing tools can do it

--

  - Run 1m regressions
  
  - Visualize a thousand variables
  
--

  - But these are *slow*
  
--

- This topic: letting **algorithms** learn for you!

--

  - Today: .red[clustering]

---

# Clustering

--

- Identify observations that belong to groups

--

  - Similarities &rarr; group belonging
  
--

- Part of broader set of methods to identify underlying "structure"

--

  - Today: *k*-means clustering algorithm
  
---

# *k*-means Clustering

--

- *k*: number of clusters (i.e., groups)

--

- Algorithm assigns each observation to these $1\dots k$ groups

--

  1. Choose initial "centroids" at random

--
  
  2. Assign observations to each centroid based on "Euclidean distance"

--
  
  3. Calculate new centroid based on mean of each variable

--
  
  4. Repeat until assignments stabilize
  
--

<center><img src="https://media.tenor.com/eRjjRricmzMAAAAM/krule-john-c-reilly.gif"></center>

---

# Euclidean Distance

```{r,message = F,warning = F,echo = F,fig.height=5,fig.width=5}
require(tidyverse)
df <- data.frame(x = c(1),
                 y = c(3))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10))
```

---

# Euclidean Distance

```{r,echo = F,fig.height=5,fig.width=5}
df <- data.frame(x = c(1,3),
                 y = c(3,3))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10))
```

---

# Euclidean Distance

```{r,echo = F,fig.height=5,fig.width=5}
df <- data.frame(x = c(1,3),
                 y = c(3,3))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'segment',x = c(1),y = 2.5,xend = 3,yend = 2.5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm")))
```

---

# Euclidean Distance

```{r,echo = F,fig.height=5,fig.width=5}
df <- data.frame(x = c(1,3,3),
                 y = c(3,3,5))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'segment',x = c(1),y = 2.5,xend = 3,yend = 2.5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm"))) + 
  annotate(geom = 'segment',x = 3.35,y = 3,xend = 3.35,yend = 5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm")))
```

---

# Euclidean Distance

```{r,echo = F,fig.height=5,fig.width=5}
df <- data.frame(x = c(1,3,3),
                 y = c(3,3,5))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'segment',x = c(1),y = 2.5,xend = 3,yend = 2.5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm"))) + 
  annotate(geom = 'segment',x = 3.35,y = 3,xend = 3.35,yend = 5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm"))) + 
  annotate(geom = 'segment',x = .9,y = 3.5,xend = 2.9,yend = 5.5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm")))
```

---

# Euclidean Distance

```{r,echo = F,fig.height=5,fig.width=5}
df <- data.frame(x = c(1,3,3),
                 y = c(3,3,5))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'segment',x = c(1),y = 2.5,xend = 3,yend = 2.5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm"))) + 
  annotate(geom = 'segment',x = 3.35,y = 3,xend = 3.35,yend = 5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm"))) + 
  annotate(geom = 'segment',x = .9,y = 3.5,xend = 2.9,yend = 5.5,
           arrow = arrow(ends = "both", angle = 90, length = unit(.2,"cm"))) + 
  annotate(geom = 'label',x = c(2,4,1.5),y = c(2,4,5),label = c('a','b','c'))
```

--

- $c^2 = a^2 + b^2$ &rarr; $c = \sqrt{a^2 + b^2}$

--

- $a^2 = (x_2 - x_1)^2 + (y_2 - y_1)^2$ & $b^2 = (x_3 - x_2)^2 + (y_3 - y_2)^2$

--

- General: $\sqrt{\sum_i (q_i - p_i)^2}$

---

# Centroids

- The center of some data

```{r,echo = F,fig.height=5,fig.width=5}
df <- data.frame(x = c(1,3,3),
                 y = c(3,3,5))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10))
```

---

# Centroids

- Initially chosen at random by the algorithm

```{r,echo = F,fig.height=5,fig.width=5}
centroid <- data.frame(x = c(1.5,3.5),
                       y = c(4,4.5))

df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10))
```

---

# Cluster Assignment

- Calculate Euclidean Distance for each observation

```{r,echo = F,fig.height=5,fig.width=5}
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') + 
  annotate(geom = 'segment',x = c(1,1),y = c(3,3),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10))
```

---

# Cluster Assignment

- Calculate Euclidean Distance for each observation

```{r,echo = F,fig.height=5,fig.width=5}
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') +
  # annotate(geom = 'segment',x = c(1,1),y = c(3,3),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'point',x = 1,y = 3,size = 3,color = 'red')
```

---

# Cluster Assignment

- Calculate Euclidean Distance for each observation

```{r,echo = F,fig.height=5,fig.width=5}
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') +
  annotate(geom = 'segment',x = c(3,3),y = c(3,3),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'point',x = 1,y = 3,size = 3,color = 'red')
```

---

# Cluster Assignment

- Calculate Euclidean Distance for each observation

```{r,echo = F,fig.height=5,fig.width=5}
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') +
  # annotate(geom = 'segment',x = c(3,3),y = c(3,3),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'point',x = 1,y = 3,size = 3,color = 'red') + 
  annotate(geom = 'point',x = 3,y = 3,size = 3,color = 'darkgreen')
```

---

# Cluster Assignment

- Calculate Euclidean Distance for each observation

```{r,echo = F,fig.height=5,fig.width=5}
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') +
  annotate(geom = 'segment',x = c(3,3),y = c(5,5),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'point',x = 1,y = 3,size = 3,color = 'red') + 
  annotate(geom = 'point',x = 3,y = 3,size = 3,color = 'darkgreen')
```

---

# Cluster Assignment

- Calculate Euclidean Distance for each observation

```{r,echo = F,fig.height=5,fig.width=5}
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = c('red','darkgreen'),shape = '+') +
  # annotate(geom = 'segment',x = c(3,3),y = c(5,5),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'point',x = 1,y = 3,size = 3,color = 'red') + 
  annotate(geom = 'point',x = 3,y = 3,size = 3,color = 'darkgreen') + 
  annotate(geom = 'point',x = 3,y = 5,size = 3,color = 'darkgreen')
```

---

# Recalculate Centroids

- Set new centroids to mean of $x$ and $y$ among members

```{r,echo = F,fig.height=5,fig.width=5}
centroid2 <- data.frame(x = c(1,3),y = c(3,4))
df %>%
  ggplot(aes(x = x,y = y)) + 
  geom_point(size = 3) + 
  annotate(geom = 'point',x = centroid$x,y = centroid$y,size = 10,color = 'grey70',shape = '+') +
  annotate(geom = 'point',x = centroid2$x,y = centroid2$y,size = 10,color = c('red','darkgreen'),shape = '+') +
  # annotate(geom = 'segment',x = c(3,3),y = c(5,5),xend = c(1.5,3.5),yend = c(4,4.5)) + 
  scale_x_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  scale_y_continuous(breaks = seq(0,10,by = 1),limits = c(0,10)) + 
  annotate(geom = 'point',x = 1,y = 3,size = 3,color = 'red') + 
  annotate(geom = 'point',x = 3,y = 3,size = 3,color = 'darkgreen') + 
  annotate(geom = 'point',x = 3,y = 5,size = 3,color = 'darkgreen')
```

--

- [A simulation](http://tech.nitoyon.com/en/blog/2013/11/07/k-means/)

---

# Clustering to Learn about MCs

```{r, message=FALSE}
library(tidyverse)
dat <- read_csv('https://raw.githubusercontent.com/jbisbee1/ISP_Data_Science_2024/main/data/H097_members.csv')
glimpse(dat)
```

---

# DW-NOMINATE

- DW-NOMINATE is a measure of how frequently different legislators vote together

--

- Often interpreted as "ideology"

--

- Two-dimensions:

--

  1. Standard left-right ideology (size of gov, redistribution, etc.)
  
  2. Second dimension changes, but typically **salient social issues**
  
--

- Can $k$-means clustering help us learn about legislators?

---

# 97th Congress (1981-1983)

```{r,message = F,warning = F}
require(scales)
library(plotly)
gg <- dat %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,
             text = bioname)) + 
  geom_point() + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2')
```

---

# 97th Congress (1981-1983)

```{r,warning = F,echo = F}
ggplotly(gg,tooltip = "text")
```

---

# Intuition Check

--

- Can we see some clusters?

  - What do we think these are?
  
--

- Let's try estimating $k$-means!

--

- Function `kmeans(x,centers,iter.max,nstart)`

--

  - `x` is the data (only select the columns of interest!)
  
  - `centers` is the number of centroids
  
  - `iter.max` maximum amount of "steps"
  
  - `nstart` how many times to re-estimate
  
---

# Clustering on Ideology

- First, some light wrangling (convert numeric party code to character)

```{r}
datClust <- dat %>% 
  mutate(party = ifelse(party_code == 200,'R',
                        ifelse(party_code == 100,'D','I'))) %>%
  mutate(nameParty = paste0(bioname,' (',party,')')) %>%
  select(nominate_dim1,nominate_dim2,nameParty) %>% drop_na()
```

---

# Clustering on Ideology

- Second, estimate `kmeans()` function

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
            centers = 2)

m
```

---

# Clustering on Ideology

- Easier to see output with the help of `tidymodels` package

```{r,message=F,warning=F}
require(tidymodels)
tidy(m)
```

--

- First two columns are the **locations** of the centroids

- `size` is the number of observations associated with each group

- `withinss` is the **errors** each centroid makes

---

# Clustering on Ideology

- Third, plot points and color by cluster

```{r}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>% # Add cluster to data
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, 
             color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster")
```

---

# Clustering on Ideology

```{r}
ggplotly(ggClust,tooltip = 'text')
```


---

# More Clusters

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
            centers = 3)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       subtitle = '# Clusters = 3',
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```


---

# More Clusters

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
            centers = 4)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       subtitle = '# Clusters = 4',
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```


---

# More Clusters

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
            centers = 5)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       subtitle = '# Clusters = 5',
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```

---

# How many clusters?

--

- Recall from regression that we are interested in **errors**

--

- What are "errors" in the context of clustering?

--

```{r,echo = F}
m <- datClust %>% select(nominate_dim1,nominate_dim2) %>%
  kmeans(centers = 2)

cents <- data.frame(m$centers)

toplot <- datClust %>%
  mutate(clust = m$cluster) 

toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_point(data = cents,aes(x = nominate_dim1,y = nominate_dim2),
             inherit.aes = F,shape = '+',size = 10) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```

---

# How many clusters?

- Recall from regression that we are interested in **errors**

- What are "errors" in the context of clustering?

```{r,echo = F}
toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_segment(data = toplot %>%
                 filter(clust == 1),
               aes(x = nominate_dim1,y = nominate_dim2),xend = cents$nominate_dim1[1],yend = cents$nominate_dim2[1]) +
  geom_segment(data = toplot %>%
                 filter(clust == 2),
               aes(x = nominate_dim1,y = nominate_dim2),xend = cents$nominate_dim1[2],yend = cents$nominate_dim2[2]) +
  geom_point(data = cents,aes(x = nominate_dim1,y = nominate_dim2),
             inherit.aes = F,shape = '+',size = 10) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```


---

# How many clusters?

- Recall from regression that we are interested in **errors**

- What are "errors" in the context of clustering?

- Just the sum of each observation's distance from its centroid!

--

  - Within Sum of Squares (**WSS**)

```{r,message=F,warning=F}
tidy(m)
```

---

# So...how many?!

- Want to choose a number of clusters that reduces the total **WSS**

--

```{r}
m.cluster <- datClust %>%
  select(-nameParty) %>% # Same as selecting two dimensions
  kmeans(centers = 3)
```

```{r,echo = F,warning=F,message=F}
cents <- data.frame(m.cluster$centers) %>%
  mutate(clust = row_number()) %>%
  rename(xend = nominate_dim1,yend = nominate_dim2)

cents$wss <- m.cluster$withinss

toplot <- datClust %>%
  as_tibble() %>%
  mutate(clust = m.cluster$cluster) %>%
  left_join(cents)

toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_segment(aes(x = nominate_dim1,y = nominate_dim2,xend = xend,yend = yend)) + 
  geom_point(data = cents,aes(x = xend,y = yend),
             inherit.aes = F,shape = '+',size = 10) + 
  geom_label(data = cents,aes(x = xend,y = yend,label = round(wss,1)),inherit.aes = F,hjust = 0,vjust = 0,nudge_x = .1,nudge_y = .1) + 
  annotate(geom = 'label',x = 0,y = 1,label = paste0('Tot WSS = ',round(m.cluster$tot.withinss,1))) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```

---

# So...how many?!

- Want to choose a number of clusters that reduces the total **WSS**

```{r}
m.cluster <- datClust %>%
  select(-nameParty) %>%
  kmeans(centers = 4)
```

```{r,echo = F,warning=F,message=F}
cents <- data.frame(m.cluster$centers) %>%
  mutate(clust = row_number()) %>%
  rename(xend = nominate_dim1,yend = nominate_dim2)

cents$wss <- m.cluster$withinss

toplot <- datClust %>%
  as_tibble() %>%
  mutate(clust = m.cluster$cluster) %>%
  left_join(cents)

toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_segment(aes(x = nominate_dim1,y = nominate_dim2,xend = xend,yend = yend)) + 
  geom_point(data = cents,aes(x = xend,y = yend),
             inherit.aes = F,shape = '+',size = 10) + 
  geom_label(data = cents,aes(x = xend,y = yend,label = round(wss,1)),inherit.aes = F,hjust = 0,vjust = 0,nudge_x = .1,nudge_y = .1) + 
  annotate(geom = 'label',x = 0,y = 1,label = paste0('Tot WSS = ',round(m.cluster$tot.withinss,1))) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```

---

# So...how many?!

- Want to choose a number of clusters that reduces the total **WSS**

```{r}
m.cluster <- datClust %>%
  select(-nameParty) %>%
  kmeans(centers = 5)
```

```{r,echo = F,warning=F,message=F}
cents <- data.frame(m.cluster$centers) %>%
  mutate(clust = row_number()) %>%
  rename(xend = nominate_dim1,yend = nominate_dim2)

cents$wss <- m.cluster$withinss

toplot <- datClust %>%
  as_tibble() %>%
  mutate(clust = m.cluster$cluster) %>%
  left_join(cents)

toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_segment(aes(x = nominate_dim1,y = nominate_dim2,xend = xend,yend = yend)) + 
  geom_point(data = cents,aes(x = xend,y = yend),
             inherit.aes = F,shape = '+',size = 10) + 
  geom_label(data = cents,aes(x = xend,y = yend,label = round(wss,1)),inherit.aes = F,hjust = 0,vjust = 0,nudge_x = .1,nudge_y = .1) + 
  annotate(geom = 'label',x = 0,y = 1,label = paste0('Tot WSS = ',round(m.cluster$tot.withinss,1))) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```

---

# So...how many?!

- Want to choose a number of clusters that reduces the total **WSS**

```{r}
m.cluster <- datClust %>%
  select(-nameParty) %>%
  kmeans(centers = 10)
```

```{r,echo = F,warning=F,message=F}
cents <- data.frame(m.cluster$centers) %>%
  mutate(clust = row_number()) %>%
  rename(xend = nominate_dim1,yend = nominate_dim2)

cents$wss <- m.cluster$withinss

toplot <- datClust %>%
  as_tibble() %>%
  mutate(clust = m.cluster$cluster) %>%
  left_join(cents)

toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_segment(aes(x = nominate_dim1,y = nominate_dim2,xend = xend,yend = yend)) + 
  geom_point(data = cents,aes(x = xend,y = yend),
             inherit.aes = F,shape = '+',size = 10) + 
  geom_label(data = cents,aes(x = xend,y = yend,label = round(wss,1)),inherit.aes = F,hjust = 0,vjust = 0,nudge_x = .1,nudge_y = .1) + 
  annotate(geom = 'label',x = 0,y = 1,label = paste0('Tot WSS = ',round(m.cluster$tot.withinss,1))) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```

---

# So...how many?!

- Want to choose a number of clusters that reduces the total **WSS**

```{r}
m.cluster <- datClust %>%
  select(-nameParty) %>%
  kmeans(centers = 30)
```

```{r,echo = F,warning=F,message=F}
cents <- data.frame(m.cluster$centers) %>%
  mutate(clust = row_number()) %>%
  rename(xend = nominate_dim1,yend = nominate_dim2)

cents$wss <- m.cluster$withinss

toplot <- datClust %>%
  as_tibble() %>%
  mutate(clust = m.cluster$cluster) %>%
  left_join(cents)

toplot %>%
  ggplot(aes(x = nominate_dim1,y = nominate_dim2,color = factor(clust))) + 
  geom_point() + 
  geom_segment(aes(x = nominate_dim1,y = nominate_dim2,xend = xend,yend = yend)) + 
  geom_point(data = cents,aes(x = xend,y = yend),
             inherit.aes = F,shape = '+',size = 10) + 
  geom_label(data = cents,aes(x = xend,y = yend,label = round(wss,1)),inherit.aes = F,hjust = 0,vjust = 0,nudge_x = .1,nudge_y = .1) + 
  annotate(geom = 'label',x = 0,y = 1,label = paste0('Tot WSS = ',round(m.cluster$tot.withinss,1))) + 
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster") + 
  theme(legend.position = 'none')
```

---

# So...how many?!

- But there's a trade-off!

--

  - Accuracy versus **parsimony**
  
--

- Simple rule: look for the "elbow"

```{r}
totWSS <- NULL
for(k in 1:10) {
  m.cluster <- datClust %>%
    select(-nameParty) %>%
    kmeans(centers = k,nstart = 25)
  totWSS <- data.frame(totWSS = m.cluster$tot.withinss,
             k = k) %>%
    bind_rows(totWSS)
}
```

---

# Looking for the "elbow"

```{r}
totWSS %>%
  ggplot(aes(x = k,y = totWSS)) + 
  geom_line() + geom_point() + 
  labs(x = 'Number of Clusters',y = 'Total WSS') + 
  scale_x_continuous(breaks = 1:10)
```


---

# Clustering on Ideology

- Note that we need to `set.seed()`! Centroid starting points are **random**!

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
                    centers = 2)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```

---

# Clustering on Ideology

- Note that we need to `set.seed()`! Centroid starting points are **random**!

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
                    centers = 2)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```

---

# Clustering on Ideology

- Note that we need to `set.seed()`! Centroid starting points are **random**!

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
                    centers = 2)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```

---

# Clustering on Ideology

- Note that we need to `set.seed()`! Centroid starting points are **random**!

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
                    centers = 2)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="97th Congress Ideology",
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```

---

# Clustering Randomness

- Can overcome with `nstart`

--

  - Attempts multiple initial centroids and chooses the "best"
  
```{r}
set.seed(42)
c1 <- kmeans(datClust %>% select(-nameParty),centers = 2,nstart = 25)

set.seed(123)
c2 <- kmeans(datClust %>% select(-nameParty),centers = 2,nstart = 25)

table(c1$cluster,c2$cluster)
```




---

# Is Polarization Increasing?

- Compare 97th Congress (1981-1983) to 117th Congress (2021-2023)

```{r,warning=F,message=F}
dat <- read_csv('https://raw.githubusercontent.com/jbisbee1/ISP_Data_Science_2024/main/data/H117_members.csv')
datClust <- dat %>% 
  mutate(party = ifelse(party_code == 200,'R',
                        ifelse(party_code == 100,'D','I'))) %>%
  mutate(nameParty = paste0(bioname,' (',party,')')) %>% # combine name + party
  select(nominate_dim1,nominate_dim2,nameParty) %>% drop_na()
```

- Check for the "elbow"

```{r}
totWSS <- NULL
for(k in 1:10) {
  m.cluster <- datClust %>%
    select(-nameParty) %>% kmeans(centers = k,nstart = 25)
  totWSS <- data.frame(totWSS = m.cluster$tot.withinss,k = k) %>%
    bind_rows(totWSS)
}
```

---

# Check for the "elbow"

```{r}
totWSS %>%
  ggplot(aes(x = k,y = totWSS)) + 
  geom_line() + geom_point() + 
  labs(x = 'Number of Clusters',y = 'Total WSS') + 
  scale_x_continuous(breaks = 1:10)
```

---

# Growing polarization?

```{r}
m <- kmeans(x = datClust %>% select(nominate_dim1,nominate_dim2),
            centers = 2)
```
```{r,echo = F}
ggClust <- datClust %>%
  mutate(cluster = m$cluster) %>%
  ggplot(aes(x = nominate_dim1, y = nominate_dim2, color = factor(cluster),
             text=nameParty)) +
  geom_point() +
  labs(x = 'DW-Nominate Dimension 1',
       y = 'DW-Nominate Dimension 2',
       title="117th Congress Ideology",
       color = "Cluster")
ggplotly(ggClust,tooltip = 'text')
```


---

# BREAK

---

# Agenda

1. Tweets as data

2. Words &rarr; topics

3. Application

---

# Social Media

- Unprecedented access to our leaders

--

  - (If they let us)
  
--

<center><img src="https://kajabi-storefronts-production.kajabi-cdn.com/kajabi-storefronts-production/themes/2271049/settings_images/TFQe2IEJSWuLQrrYueXd_pasted_image_0_28.png" width="80%"></center>

---

# Social Media

- Unprecedented access to our leaders 

  - (If they let us)

<center><img src="https://media-cldnry.s-nbcnews.com/image/upload/newscms/2020_29/3391138/200618-donald-trump-cellphone-smartphone-cell-ac-1059p.jpg" width="80%"></center>

---

# Social Media

- For researchers, social media is two things

--

  1. A source of .red[data]
  
--

  2. An object of .blue[interest]
  
--

<center><img src="https://ichef.bbci.co.uk/news/1024/cpsprodpb/173D6/production/_116409159_tweet6.png" width="80%"></center>

---

# Twitter as Data

- Not the most popular social media app

<center><img src="https://www.pewresearch.org/internet/wp-content/uploads/sites/9/2021/04/PI_2021.04.07_social-media_0-01.png?w=640" width="60%"></center>

---

# Twitter as Data

- But an outsized platform for the elite

--

- As of 2020

--

  - every U.S. governor had a Twitter account
  
--

  - 49 had a Facebook account
  
--

  - 44 had an Instagram account

--

  - 44 had a YouTube account
  
--

- In professional networks, particularly media, Twitter is almost *lingua franca*

---

# Twitter as Data

- Today?

--

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Twitter has had a massive drop in revenue, due to activist groups pressuring advertisers, even though nothing has changed with content moderation and we did everything we could to appease the activists.<br><br>Extremely messed up! Theyâ€™re trying to destroy free speech in America.</p>&mdash; Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1588538640401018880?ref_src=twsrc%5Etfw">November 4, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

---

# Trump and Twitter

- Today, looking at Trump's tweets

--

  - Treating it as a .red[data source]
  
--

  - What can his tweets tell us about the man?
  
```{r,message=F,warning=F}
require(tidyverse)
tweets <- read_rds(file="https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/Trumptweets.Rds")
```

--

- The **process**

--

  - Univariate visualisation: how often does he tweet?
  
--

```{r}
p <- tweets %>% 
  count(Tweeting.date) %>%
  ggplot() +
  geom_point(aes(x=Tweeting.date,y=n),alpha=.4) +
  scale_x_date(date_breaks = 'years',date_labels = '%Y') + 
  labs(x="Date",y="Number of Tweets",title="Tweeting by Trump")
```

---

# Trump and Twitter

```{r}
p
```

---

# Trump and Twitter

- Research questions abound!

--

1. What happened in...
  
  - June of 2011?
    
  - June of 2012?
    
  - November of 2016? (duh)
    
--

2. Overtime increase during presidency?

--

3. Others?

---

# Trump and Twitter

- .blue[Research Question:] Did Trump's twitter account benefit from his presidency?

--

```{r,message = F}
require(scales)
p <- tweets %>% 
  group_by(Tweeting.date) %>%
  summarize(AvgRetweet = mean(retweets)) %>%
  ggplot() +
  geom_point(aes(x=Tweeting.date,y=AvgRetweet),alpha=.4) +
  labs(x="Date",y="Average Retweets",title="Tweeting by Trump") +
  scale_y_continuous(label=comma)
```

---

# Trump and Twitter

- .blue[Research Question:] Did Trump's twitter account benefit from his presidency?

- **Yes**

```{r,echo = F}
p
```


---

# Looking with `plotly`

```{r message=FALSE}
library(plotly)
gg <- tweets %>%
  filter(retweets > quantile(retweets,.75)) %>% 
  ggplot(aes(x=Tweeting.date,y=retweets,text=stringr::str_wrap(content,width = 60))) +
  geom_point(alpha=.4) +
  labs(x="Date",y="Retweets",title="Tweeting by Trump") +
  scale_y_continuous(label=scales::comma)
```

---

# Looking with `plotly`

```{r}
ggplotly(gg,tooltip = "text")
```

---

# Trump's Censored Tweets

- What was Trump tweeting about when he was flagged by Twitter?

```{r}
tweets %>%
  filter(is_flagged) %>% # Indicator for Twitter flag
  ggplot(aes(x = Tweeting.date)) + 
  geom_bar()
```

# Trump's Censored Tweets

- Proportion of flagged tweets instead of counts

```{r,echo=F,warning=F,message=F}
gg <- tweets %>%
  count(Tweeting.date,is_flagged) %>%
  group_by(Tweeting.date) %>%
  mutate(totTweets = sum(n)) %>%
  ungroup() %>%
  mutate(prop = n / totTweets) %>%
  filter(is_flagged) %>%
  ggplot(aes(x = Tweeting.date,y = prop)) + 
  geom_point() + 
  scale_y_continuous(labels = scales::percent) + 
  labs(x = 'Date',y = 'Proportion of Total Tweets Flagged')
```

```{r}
gg
```

---

# Looking at content

- We could just look at the flagged tweets themselves

```{r,echo=F}
gg <- tweets %>%
  filter(is_flagged) %>%
  ggplot(aes(x = Tweeting.date,y = retweets,text = stringr::str_wrap(content,width = 60))) + 
  geom_point() + 
  scale_y_continuous(labels = scales::percent) + 
  labs(x = 'Date',y = 'Total Retweets')
```

```{r}
ggplotly(gg)
```

---

# Looking at content

- Or we can look at statistical summaries of Trump's tweets

--

  1. Tweets as .red[data]: we can understand him better
  
  2. Tweets as .blue[object of interest]: how do his tweets influence public discourse?
  
--

- We will be using pre-processed tweets

--

  - Lots of **data wrangling** went into this
  
  - See the `prepping_raw_tweets.R` file for more details

--

```{r}
tweet_words <- read_rds(file="https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/Trump_tweet_words.Rds")
```

---

# NLP Definitions

- Before we dig in, some important definitions

--
  
1. **Word / Term:** The core unit of interest

--

  - Often pre-processed to remove "stop words" and to "stem" the words
  
  - "Stop word": an uninteresting, commonly used word
  
  - "Stem / Lemmatize": the core component of a word that contains its meaning (eat, ate, eaten &rarr; eat)
  
--
  
2. **Document:** A collection of words with a single purpose / idea (i.e., a tweet, an essay)

--
  
3. **Corpus:** A collection of documents

--

4. **BOW:** Bag-of-words. Convert a **document** into a count of how many times **words** appear

--

5. **DTM:** Document-term matrix. A dataset where rows are **documents**, columns are **words**, and the values are the counts from **BOW**


---

# What does Trump tweet about?

- Core idea: word frequencies can help:

--

  - Help us understand **documents**
  
--

  - Which help us understand **authors**
  
```{r}
counts <- tweet_words %>% 
  count(word) %>%
  arrange(-n)
```

---

# What does Trump tweet about?

```{r}
counts
```

---

# What does Trump tweet about?

```{r}
p <- tweet_words %>%
  count(word, sort = TRUE) %>% # New ways of doing old things
  head(20) %>%
  ggplot(aes(x = n,y = reorder(word, n))) +
  geom_bar(stat = "identity") +
  ylab("Occurrences") +
  scale_x_continuous(label=comma)
```

---

# What does Trump tweet about?

```{r}
p
```


---

# Effect of becoming president

- Did his focus change when he became president?

```{r}
tweet_words <- tweet_words %>%
  mutate(PostPresident = Tweeting.date > as.Date("2016-11-03"))
```

--

```{r}
p <- tweet_words %>%
  count(PostPresident,word) %>%
  group_by(PostPresident) %>%
  arrange(-n) %>%
  slice(1:10) %>%
  ggplot(aes(x = n,y = reorder(word, n),
             fill = PostPresident)) +
  geom_bar(stat = "identity") +
  ylab("Occurrences") +
  scale_x_continuous(label=comma)
```

---

# Effect of becoming president

```{r}
p
```

---

# Document Term Matrix

- "DTM" counts all the words in each document

--

- In this case, a "document" is a tweet

```{r}
dtm <- tweet_words %>%
  count(document,word)
glimpse(dtm)
```

---

# Document Term Matrix

- However, each tweet is very short

--

- Let's consider the `Tweeting.date` the document

--

  - Concept: What is Trump tweeting about on a given day?
  
```{r}
dtm <- tweet_words %>%
  count(Tweeting.date,word) %>%
  group_by(word) %>%
  mutate(tot_n = sum(n)) %>% # Also calculate TOTAL number of times a word appears
  ungroup()
```

---

# Wrangle

- Extremely rare words should be dropped (typos, etc.)

```{r}
dtm %>%
  arrange(tot_n) %>% head() # Trump tweeted "barnesandnoblecom" only once in his life

dtm <- dtm %>%
  filter(tot_n > 20) # Drop these rarely occurring words
```


---

# Analyzing BOW

- Some words are frequently found in many documents

--

- We want to find words that are **uniquely** used

--

  - "Unique" &rarr; used frequently in one document but not in any others
  
--

- "TF-IDF": Term frequency-inverse document frequency

--

- "TF": $\frac{\text{word count}}{\text{total words}}$

- "DF": $\frac{\text{documents with word}}{\text{total documents}}$

--

  - "IDF": Just invert it $\frac{\text{total documents}}{\text{documents with word}}$
  
$$tf-idf(w,d) = tf(w,d) \times log \left( \frac{N}{df(w)}\right) $$

---

# TF-IDF

```{r,warning=F,message=F}
require(tidytext) # Required to calculate TF-IDF
dtm.tfidf <- bind_tf_idf(tbl = dtm, term = word, document = Tweeting.date, n = n) # Calculate TF-IDF
dtm.tfidf  %>%
  select(word,tf_idf) %>%
  distinct() %>%
  arrange(-tf_idf) %>%
  slice(1:10)
```

---

# $K$-means

- How to summarize this? $k$-means clustering!

--

- Recall that `kmeans()` function clusters over every column in a data frame

--

- `dtm.tfidf` is organized "long" (i.e., each row is a word-by-document)

--

- Want to convert to "wide" (i.e., rows are documents, columns are words)

--

- Previously used `spread()`, but for *k*-means with text: `cast_dtm()`

--

```{r}
castdtm <- cast_dtm(data = dtm.tfidf, document = Tweeting.date, term = word, value = tf_idf)
```

--

- Now let's calculate `kmeans()` (this will take a few seconds)

```{r}
set.seed(42)
km_out <- kmeans(castdtm, 
                 centers = 50, # Number of "topics"
                 nstart = 5)
```

---

# Looking at Clusters

- Some quick wrangling

```{r,warning=F,message=F}
require(tidymodels)
km_out_tidy <- tidy(km_out) %>%
  gather(word,mean_tfidf,-size,-cluster,-withinss) %>% # Convert to long data
  mutate(mean_tfidf = as.numeric(mean_tfidf)) # Calculate average TF-IDF
km_out_tidy
```

---

# Looking at Clusters

- And can plot! (Just look at first 10 "topics")

```{r}
p <- km_out_tidy %>%
  filter(cluster %in% 1:9) %>%
  group_by(cluster) %>%
  arrange(-mean_tfidf) %>%
  slice(1:10) %>%
  ggplot(aes(x = mean_tfidf,y = reorder(word,mean_tfidf),
             fill = factor(cluster))) + 
  geom_bar(stat = 'identity') + 
  facet_wrap(~cluster,scales = 'free') + 
  labs(title = 'k-means Clusters',
       subtitle = 'Clustered by TF-IDF',
       x = 'Centroid',
       y = NULL,
       fill = 'Cluster ID')
```

---

# Looking at Clusters

```{r}
p
```

---

# Looking at clusters

- What are these clusters?

--

- Let's look at the most popular topics

```{r}
(tops <- km_out_tidy %>%
  select(size,withinss,cluster) %>%
  distinct() %>%
  arrange(desc(size)) %>%
    slice(1:5))

p <- km_out_tidy %>%
  filter(cluster %in% tops$cluster) %>%
  group_by(cluster) %>%
  arrange(-mean_tfidf) %>%
  slice(1:10) %>%
  ggplot(aes(x = mean_tfidf,y = reorder(word,mean_tfidf),
             fill = factor(cluster))) + 
  geom_bar(stat = 'identity') + 
  facet_wrap(~cluster,scales = 'free') + 
  labs(title = 'k-means Clusters',
       subtitle = 'Clustered by TF-IDF',
       x = 'Centroid',
       y = NULL,
       fill = 'Cluster ID')
```

---

# Looking at clusters

```{r}
p
```

---

# Optimal number of clusters?

- We know how to do this already! Elbow plot!

```{r}
set.seed(42)
totWSS <- NULL
for(k in c(1,10,50,100,250,500,1000)) {
  km_out <- kmeans(castdtm, 
                 centers = k,
                 nstart = 5)
  
  totWSS <- data.frame(totWSS = km_out$tot.withinss,
                       k = k) %>%
    bind_rows(totWSS)
}

p <- totWSS %>%
  ggplot(aes(x = k,y = totWSS)) + 
  geom_point() + 
  geom_line()
```

---

# Optimal number of clusters?

```{r}
p
```



---

# Conclusion

- $k$-means clustering on text &rarr; **topics**

--

- As always, this is a deep area of study

--

  - Superior methods are out there (Latent Dirichlet Allocation, Structural Topic Modeling, etc.)
  
--

- NOTE: even with text, always start with simple descriptives

--

  - **Looking** at your data is the heart of data science


