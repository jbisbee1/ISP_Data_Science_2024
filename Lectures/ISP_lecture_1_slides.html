<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Intro to Data Science</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Bisbee" />
    <script src="libs/header-attrs-2.27/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Intro to Data Science
]
.subtitle[
## What <code>R</code> we doing?
]
.author[
### Prof. Bisbee
]
.institute[
### Seoul National University
]
.date[
### Slides Updated: 2024-06-30
]

---


&lt;style type="text/css"&gt;
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
&lt;/style&gt;



# Agenda

1. Meet the instructor

2. Course Motivation

3. Course Objectives

4. ChatGPT and data science
  
5. Course Expectations &amp; Syllabus review

BREAK

6. Intro to `R`

---

# Meet the instructor

- Education

--

  - PhD from NYU Politics in 2019

  - Postdocs at Princeton Niehaus &amp; NYU CSMaP
  
--

- Published some things

--

  - Methods-ey: external validity [1](https://www.journals.uchicago.edu/doi/full/10.1086/691280?af=R), [2](https://www.cambridge.org/core/journals/american-political-science-review/article/testing-social-science-network-theories-with-online-network-data-an-evaluation-of-external-validity/4BF517F10F38DFB574FED4A3D805B613); measurement [3](https://www.cambridge.org/core/journals/american-political-science-review/article/barp-improving-mister-p-using-bayesian-additive-regression-trees/630866EB47F9366EDB3C22CFD951BB6F), [4](https://www.cambridge.org/core/journals/political-analysis/article/geographic-boundaries-and-local-economic-conditions-matter-for-views-of-the-economy/32C8C058B8E16CAD48374F95B2B1B3EF)

  - Substantive: economics &amp; populism [1](https://www.tandfonline.com/doi/full/10.1080/13501763.2019.1678662); Covid-19 &amp; U.S. politics [2](https://www.journals.uchicago.edu/doi/10.1086/716969),  [3](https://www.cambridge.org/core/journals/american-political-science-review/article/flight-to-safety-covidinduced-changes-in-the-intensity-of-status-quo-preference-and-voting-behavior/AE84D93BAF8B27284DD8F6A75DE5D18A); IPE [4](https://doi.org/10.1017/S0020818319000109); academic naval-gazing [5](https://www.cambridge.org/core/journals/perspectives-on-politics/article/abs/polisci-twitter-a-descriptive-analysis-of-how-political-scientists-use-twitter-in-2019/C8A193C3E939C1ABCD4600DFE8AEF79A?utm_source=hootsuite&amp;utm_medium=twitter&amp;utm_campaign=PPS_Dec20)

  - Popular press: [1](https://www.washingtonpost.com/news/monkey-cage/wp/2018/04/04/losing-jobs-to-free-trade-makes-americans-more-protectionist-and-nativist/), [2](https://www.washingtonpost.com/politics/2020/04/02/sanders-was-losing-biden-anyway-he-lost-more-areas-with-coronavirus-cases/?utm_medium=social&amp;utm_source=twitter&amp;utm_campaign=wp_monkeycage), [Podcasts](https://www.niskanencenter.org/did-chinese-trade-competition-increase-nativism-and-elect-trump/)
  
--

- Work

--

  - World Bank / IFC
  
  - MarketCast

---

# Meet the instructor

- Current research

--

  - .red[YouTube] + .blue[polarization]

--

  - .red[Twitter] + .blue[misinformation]
  
--

  - .red[Telegram] + .blue[white supremacists]
  
--

  - .red[Stocks] + .blue[politicians]

---

# Why are you here?

--

background-image: url(./figs/fight_ds_econ.PNG)
background-size: contain

--

background-image: url(./figs/fight_ds_ps.PNG)
background-size: contain

--

background-image: url(./figs/fight_ds_cs.PNG)
background-size: contain

--

background-image: url(./figs/fight_ds_stats.PNG)
background-size: contain

--

background-image: url(./figs/fight_ds_stem.PNG)
background-size: contain

---

# Is this all just a fad?

--

- No


&lt;center&gt;&lt;img src="figs/datagrowth.png" width = "75%"&gt;&lt;/center&gt;


---

# Is this all just a fad?

- But there are faddish qualities

&lt;center&gt;&lt;img src="figs/hype_cycle.png" width = "75%"&gt;&lt;/center&gt;


---

# So what IS data science?

- Split into two camps

--

1. .blue[Research] camp

--

  - Focused on **answering a research question**
  
  - Follows the "scientific method"
  
  - Goal: contribute to knowledge
  
  - Domain: academia
  
--
  
2. .red[Prediction] camp

--

  - Focused on **making a prediction**
  
  - Typically unconcerned with theory or *why* a model works
  
  - Goal: inform a decision / policy
  
  - Domain: private sector

--
  
(3. .red[Learning] camp)

--

  - Let the data "speak"
  
  - (More of a subset of camps 1 and 2)
  
---

# The Two Camps

&lt;center&gt;&lt;img src="figs/camps1.png" width="80%"&gt;&lt;/center&gt;

---

# The Two Camps

&lt;center&gt;&lt;img src="figs/camps2.png" width="80%"&gt;&lt;/center&gt;

---

# The Two Camps

&lt;center&gt;&lt;img src="figs/camps3.png" width="80%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

- The scientific method

  1. .red[Observation] &amp;rarr; .blue[Question]

--

  2. .blue[Theory] &amp;rarr; .blue[Hypothesis]

--

  3. .red[Data Collection / Wrangling] &amp;rarr; .red[Analysis]

--

  4. .red[Results] &amp;rarr; .blue[Conclusion]
  
--

&lt;img src="ISP_lecture_1_slides_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;



---

# .blue[Research] Camp

- The scientific method

  1. .red[Observation] &amp;rarr; .blue[Question]

  2. .blue[Theory] &amp;rarr; .blue[Hypothesis]

  3. .red[Data Collection / Wrangling] &amp;rarr; .red[Analysis]

  4. .red[Results] &amp;rarr; .blue[Conclusion]

&lt;img src="ISP_lecture_1_slides_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;



---

# .blue[Research] Camp

--

&lt;center&gt;&lt;img src="figs/brown_et_al.png" width=80%&gt;&lt;/center&gt;

---

# .blue[Research] Camp

1. **.red[Observation]** &amp;rarr; **.blue[Question]**
  
--

  - Observation is facilitated by .red[data] (Descriptive analysis)

--

&lt;img src="figs/transparency_tube.png" width="100%"&gt;

---

# .blue[Research] Camp

1. **.red[Observation]** &amp;rarr; **.blue[Question]**

  - Observation is facilitated by .red[data] (Descriptive analysis)

&lt;img src="figs/recs_example_1.png" width="100%"&gt;


---

# .blue[Research] Camp

1. **.red[Observation]** &amp;rarr; **.blue[Question]**

  - Observation is facilitated by .red[data] (Descriptive analysis)

&lt;img src="figs/recs_example_2.png" width="100%"&gt;


---

# .blue[Research] Camp

1. **.red[Observation]** &amp;rarr; **.blue[Question]**

  - The question pertains to .blue[science]
  
--

  - I.e., does YouTube's algorithm put users into "echo chambers"?

--

&lt;center&gt;&lt;img src="figs/echo_chamber.png" width="60%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**
  
--

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict

--

&lt;center&gt;&lt;img src="figs/utility_1.png" width="60%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict

&lt;center&gt;&lt;img src="figs/utility_2.png" width="60%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict

&lt;center&gt;&lt;img src="figs/utility_3.png" width="60%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict

&lt;center&gt;&lt;img src="figs/utility_4.png" width="60%"&gt;&lt;/center&gt;


---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict

&lt;center&gt;&lt;img src="figs/utility_5.png" width="60%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict
  
  - YouTube wants users to watch more videos

--

.leftcol[
&lt;img src="figs/covington_et_al_2016.png" width="100%"&gt;
]

--

.rightcol[
&lt;img src="figs/yt_rec_algo.png" width="100%"&gt;
]


---

# .blue[Research] Camp

&lt;ol start = 2&gt;

&lt;li&gt; **.blue[Theory]** &amp;rarr; **.blue[Hypothesis]**

  - Theorizing requires abstraction &amp; simplification

  - I.e., people (in general) avoid conflict
  
  - YouTube wants users to watch more videos

- Hypotheses fall out naturally from well-done theory

--

- **H1:** *YouTube's recommendation algorithm should suggested liberal content to liberals and conservative content to conservatives.*


---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

  - Data collection separates "Data Science"...
  
  - ...from "Science, with data"
  
&lt;center&gt;&lt;img src="figs/data_collection_1.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

  - Data collection separates "Data Science"...
  
  - ...from "Science, with data"
  
&lt;center&gt;&lt;img src="figs/data_collection_2.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

  - Data collection separates "Data Science"...
  
  - ...from "Science, with data"
  
&lt;center&gt;&lt;img src="figs/data_collection_3.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

  - Data collection separates "Data Science"...
  
  - ...from "Science, with data"
  
&lt;center&gt;&lt;img src="figs/data_collection_4.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

--

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

--

&lt;center&gt;&lt;img src="figs/emptrav_1.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_2.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_3.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_4.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_5.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_6.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_7.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_8.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_9.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_10.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_11.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_12.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_13.png" width="90%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 3&gt;

&lt;li&gt; **.red[Data Collection / Wrangling]** &amp;rarr; **.red[Analysis]**

- Analysis is informed by the .red[data] you have collected...

- ...and the .blue[hypotheses] you have generated

&lt;center&gt;&lt;img src="figs/emptrav_14.png" width="90%"&gt;&lt;/center&gt;


---

# .blue[Research] Camp

&lt;ol start = 4&gt;

&lt;li&gt; **.red[Results]** &amp;rarr; **.blue[Conclusion]**

  - Results fall out naturally from the analysis...
  
  - ...and must be interpreted in terms of the theory and hypotheses...
  
  - ...to draw conclusions

&lt;center&gt;&lt;img src="figs/ideo_dist_2.png" width="80%"&gt;&lt;/center&gt;

---

# .blue[Research] Camp

&lt;ol start = 4&gt;

&lt;li&gt; **.red[Results]** &amp;rarr; **.blue[Conclusion]**

  - Results fall out naturally from the analysis...
  
  - ...and must be interpreted in terms of the theory and hypotheses...
  
  - ...to draw conclusions

&lt;center&gt;&lt;img src="figs/ideo_dist_3.png" width="80%"&gt;&lt;/center&gt;

---

# The Two Camps

&lt;center&gt;&lt;img src="figs/camps3.png" width="80%"&gt;&lt;/center&gt;

---

# .red[Prediction] Camp

- **Goal/Problem/Challenge**: Measure the ideology of a YouTube video

---

# .red[Prediction] Camp

- **Data Wrangling**: Get matrix of links shared on political subreddits

--

&lt;center&gt;&lt;img src="figs/hard_data_2.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Get matrix of links shared on political subreddits

&lt;center&gt;&lt;img src="figs/hard_data_3.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Get matrix of links shared on political subreddits

&lt;center&gt;&lt;img src="figs/hard_data_4.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Correspondence Analysis to estimate ideology scores for subreddits

&lt;center&gt;&lt;img src="figs/hard_data_5.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Get matrix of YouTube videos shared on scored subreddits

&lt;center&gt;&lt;img src="figs/hard_data_6.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Get matrix of YouTube videos shared on scored subreddits

&lt;center&gt;&lt;img src="figs/hard_data_7.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Get matrix of YouTube videos shared on scored subreddits

&lt;center&gt;&lt;img src="figs/hard_data_8.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Get matrix of 60k YouTube videos shared on scored subreddits

&lt;center&gt;&lt;img src="figs/hard_data_9.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Data Wrangling**: Calculate video ideology as weighted mean of subreddits

&lt;center&gt;&lt;img src="figs/hard_data_10.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Model Training**: BERT transformer trained on 60k videos

&lt;center&gt;&lt;img src="figs/hard_data_12.png" width="100%"&gt;&lt;/center&gt;

---

#.red[Prediction] Camp

- **Prediction**: Measure the ideology of a YouTube video

&lt;center&gt;&lt;img src="figs/hard_data_13.png" width="100%"&gt;&lt;/center&gt;


---

# Course Objectives

- This course is the menu, not the food

--

  - Look over many different fields, methods, and tools

--

  - You pick those you like, and take more advanced classes to dig into them

--

- But we are very **hands on**

---

# Learning goals

1. Generate a sophisticated research question based on clearly described assumptions and a narrowly defined hypothesis.

--

2. Describe the data used to investigate this research question, including univariate and multivariate visualizations and summary statistics.

--

3. Apply the appropriate methods to answer the research question and evaluate the hypothesis.

--

4. Acknowledge limitations of method and results, and describe a superior empirical setting that would overcome these limitations.


---

# ChatGPT in the classroom

- Are we at the precipice of a new era in human-computer relations?

--

  - ChatGPT can achieve these learning goals!
  
--

  - But it needs to be used wisely...it is still a tool
  
--

- It can make coding (the hardest part of this class) easier

--

- But it can also prevent you from learning

---

# AI in the labor market

- McKinsey told AT&amp;T in 1980 that, by 2000, cell phones would be a niche market of 900,000 subscribers

--

- Is AI-assisted work is the future?

--

  - Profound gains in productivity already

--

- Will this be like automation and globalization for US manufacturing?
  
--

  - What skills will be valuable in 5 years? 10 years?
  
---

# AI in the labor market

--

- My answer: prepare you for both possibilities

--

  - If AI is a "fad", make sure you can do this work unassisted
  
  - If AI is the new normal, make sure you can work with it productively
  
--

- The one thing you **shouldn't** do

--

  - Take shortcuts / cheat
  
--

- You will still have an interview in which you are asked something like the following: "How is overfitting different from underfitting, and why should we care?"

--

  - **You** need to know this answer


---

# Grades

&lt;center&gt;&lt;img src="figs/rubric.png" width="40%"&gt;&lt;/center&gt;

---

# Grades: PSets

- 6 in total

--

- Posted to **Github**

--

- Due

  - Psets 1, 3, 4 and 6 due following Thursday at start of class
  
  - Psets 2 and 5 due following Monday at start of class
  
--

- Restrictions:

  - Open book / open note / open Campuswire

  - Can collaborate but submissions must be your own
  
--

- **Must submit a record of ChatGPT work with the problem set**
  
---

# Grades: Exams

- 2 in total: midterm on July 11th, final on July 25th

--

- Midterm is 15% of final grade

- Final (cumulative) is 20% of final grade


---

# Grades: Attendance

- Taken at beginning of each lecture

- 16 meetings but only 14 count toward grade

  - 0.36 points per attendance
  
- **Don't miss the midterm or the final!!**

---

# Not Graded: HW

- You should work through the homeworks prior to each lecture

--

- Open the `.Rmd` file and Knit it

--

- Read the output and try and answer the prompts

--

- **Not graded**, but enormously helpful in preparing you to keep up with lectures



---

# Honor Code

- My policy: Academic misconduct includes, but is not limited to, cheating, fabrication, plagiarism, altering graded examinations for additional credit, having another person take an examination for you, falsification of results, or facilitating academic dishonesty or as further specified in the university policy found at the website above. These and other forms of cheating are all potentially grounds for penalties including failure of the assignment or the course, as well as program- or university-level disciplinary action.

---

# Honor Code

- Violations of this policy may result in:

--

  - An F for the class (at minimum)
  
  - Suspension for a semester
  
  - Expulsion
  
--

- However, except where **explicitly noted**, this course is collaborative

--

  - Open book, open note, open internet
  
  - Can rely on Campuswire for help
  
  - Can work together on problem sets (but must submit own work)
  
--

- **Can't collaborate on exams**

---

# Resources

- Campuswire (place for **questions**)

  - Post questions on the class feed
  
--

- GitHub (place for **materials**)

  - Find all in-class materials
  
--

- TA recitations / labs (place for **hands-on help**)

- Office hours (place for **hands-on help**)
  
---

# Teaching Philosophy

&lt;center&gt;&lt;img src="figs/responsibilities_teacher_student.png" width="100%"&gt;&lt;/center&gt;

---

# Teaching Philosophy

- This course is **inherently** hard

--

  - Learning `R` is challenging
  
--

- But the goal is to **encourage** you to pursue data science

--

- As such, the **nature** of the material is at odds with the **goal** of the class

--

- My solution: grade leniently

--

  - I.e., lots of extra credit

---

# BREAK

---

# Agenda

1. Getting set up

--

  - Folder structure + `setwd()`
  
--

2. Installing software

--

  - [`R: https://cran.r-project.org/`](https://cran.r-project.org/)
  
--

  - [`RStudio: https://rstudio.com/products/rstudio/download/`](https://rstudio.com/products/rstudio/download/)

--

3. Requiring packages

--

  - `install.packages("tidyverse")` 

--

  - `require(tidyverse)`
  
--

4. Loading and manipulating data

--

  - `readRDS()`
  
--

  - `%&gt;%`

---

# Getting set up

--

- Folder structure + `setwd()`

--

  - Concept: keep everything together...
  
--

  - ...and **related**

--

.center[&lt;img src="figs/directory_1.png" width = "75%"&gt;]


---

# Getting set up

- Folder structure + `setwd()`

  - Concept: keep everything together...

  - ...and **related**

.center[&lt;img src="figs/directory_2.png" width = "75%"&gt;]



---

# Installing software

--

- [`R: https://cran.r-project.org/`](https://cran.r-project.org/)

  - Accept all defaults
  
--

- [`RStudio: https://rstudio.com/products/rstudio/download/`](https://rstudio.com/products/rstudio/download/)

  - Download the version for your OS
  
--

- Open `RStudio` and create a new rmarkdown (`.Rmd`) file

--

  - Accept defaults, give it a sensible name, delete the default text, then save it to your folder (again with a sensible name)
  
--

  - You should follow along with the lecture in this file! Take notes here! Try code here!

---

# How to type in `.Rmd`

``` markdown
# This is a header

## This is a subheader

### This is a subsubheader

This is plain text.
```
--

# This is a header

## This is a subheader

### This is a subsubheader

This is plain text.


---

# How to type in `.Rmd`

``` markdown
- This is

- a bulleted

  - List

1. This is

2. a numbered list
```

--

- This is

- a bulleted

  - List

1. This is

2. a numbered list

---

# How to type in `.Rmd`


``` markdown
**Bold font**, *italic font*, `code font`
```
--

**Bold font**, *italic font*, `code font`

--

- Most Importantly! `R` code!


```` markdown
```{r}
2+2
```
````

--


``` r
2+2
```

```
## [1] 4
```

---

# How `R` Works

--

- **O**bject **O**riented **L**anguage (**OOL**)

--

  - Objects are created with the `&lt;-` command
  
--

  - You *can* run code directly...
  


``` r
2+2
```

```
## [1] 4
```

---

# How `R` Works


- **O**bject **O**riented **L**anguage (**OOL**)

  - Objects are created with the `&lt;-` command

  - ...but most of what we'll do involves objects
  


``` r
object1 &lt;- 2+2
```

--

- Object assignment operator **saves** the output

- It **does not print** the output

--

- To see, just call the object


``` r
object1
```

```
## [1] 4
```

---

# How `R` Works


- **O**bject **O**riented **L**anguage (**OOL**)

  - Objects are created with the `&lt;-` command

  - They can be named anything (so be intuitive!)
  


``` r
three_plus_three &lt;- 2+2
three_plus_three
```

```
## [1] 4
```

---

# How `R` Works

- **O**bject **O**riented **L**anguage (**OOL**)

  - Objects are created with the `&lt;-` command

  - Objects can store many different things
  

``` r
an_element &lt;- 2+2
a_vector &lt;- c(1,2,3)
a_list &lt;- list('element1' = 2+2,
               'element2' = "hello world!",
               'element3' = runif(n = 10,min = 0,max = 10))
a_function &lt;- function(x) {
  avg_of_x &lt;- sum(x) / length(x)
  return(avg_of_x)
}
```

---

# How `R` Works

- Objects **persist!**

``` r
an_element # This object stores 2+2
```

```
## [1] 4
```

``` r
a_vector   # This object stores the integers 1, 2, and 3
```

```
## [1] 1 2 3
```

``` r
an_element*a_vector
```

```
## [1]  4  8 12
```

``` r
an_element-a_vector
```

```
## [1] 3 2 1
```

---

# A comment on comments

- If you use a # sign inside a code chunk, you can write a comment


``` r
# This is a comment. If I compile the code, nothing will happen.

# This is another comment. These are helpful for annotating my code.
```

---

# How `R` Works

- Objects **persist!**

``` r
# This object stores:
  # 1) 2+2 (named "element1")
  # 2) the text "hello world!" (named "element2")
  # 3) 10 numbers randomly drawn between 0 and 10
a_list
```

```
## $element1
## [1] 4
## 
## $element2
## [1] "hello world!"
## 
## $element3
##  [1] 2.875775 7.883051 4.089769 8.830174 9.404673 0.455565
##  [7] 5.281055 8.924190 5.514350 4.566147
```

---

# How `R` Works

- Objects **persist!**

``` r
# Let's apply our function ("a_function") to "element3" in "a_list"
a_function(x = a_list[['element3']])
```

```
## [1] 5.782475
```

--

- We could also call `element3` from `a_list` with a dollar sign


``` r
# This does the same thing as the previous slide...it just accesses element3 differently.
a_function(x = a_list$element3)
```

```
## [1] 5.782475
```

---

# How `RStudio` Works

--

- `RStudio` is a powerful way to interact with `R`

--

- In base `R`, you interact with the program via the "command line"

--

  - For example...
  
--

- But to save your work, you can write "scripts"

--

  - For example...
  
--

- *This is all cumbersome!*

--

- Enter, `RStudio`

---

# How `RStudio` Works

--

- `RStudio` allows us to:

--

  1. Write scripts
  2. Run scripts
  3. See results

--

- It is **deeply interactive**

--

  - We can highlight a line and press `ctrl+enter` / `cmd+enter` and see the result
  
--

  - **We can even do this with single objects!**
  
---

# Give it a try

- Comment **everything**

--

- Create two objects

  - `a` contains the product of 3 and 5 (`3*5`)
  
  - `b` contains five numbers `c(10,21,43,87,175)`
  
--

- Now create object `c` which is `a - b`


``` r
# INSERT CODE HERE
```

---

# Functions &amp; Packages

--

- What are `packages`?

--

  - Basically, **functions** that someone else wrote
  
--

- `R` has many functions already installed

--

  - These are known as "base `R`" and contain many useful functions

--

  - For example, `sum()` will add up a vector of numbers

--


``` r
sum(object1)
```
  
--

  - Quiz: What does the `mean()` function do? The `median()`? The `range()`?
  
--

- Other base `R` functions interact with other files

--

  - For example, `read.csv()` will load a `.csv` file
  
--

- And there are MANY **MANY** more

---

# Installing Packages

--

- In addition to the functions included in base `R`, we want more

--

- For this class, we want one called `tidyverse`

--

  - `tidyverse` contains many (hundreds?) of functions that make `R` easier
  
--

  - But it is NOT included in the base `R` set of functions
  
--

  - Therefore, we need to add it
  
--

- Use the base `R` function `install.packages("[PACKAGE NAME]")`

--

  - Specifically, `install.packages("tidyverse")`
  
---

# Requiring Packages

--

- Once installed, a package will live somewhere on your computer

--

- However, any new *instance* of `R` will not automatically load the packages

--

- We need to `require()` them to tell `R` to load them

--

  - Alternatively, we can use `library()` (but it's the same result)
  
--

- So load the `tidyverse` package with `require(tidyverse)`



--

  - NB: you need quotes for the `install.packages()` function...
  
--

    - i.e., `install.packages("tidyverse")`
    
--

  - but NOT for the `require()` function
  
--

    - i.e., `require(tidyverse)`
  
---

# Loading Data

--

- So you should be using `R` via `RStudio` with the `tidyverse` package loaded

--

- Now let's load some data

--

- You can save it locally from the course  [github page](https://github.com/jbisbee1/ISP_Data_Science_2024/blob/main/data/sc_debt.Rds) and then load it from your computer
  
--

- Or you can load it directly from the internet with the `read_rds()` function from `tidyverse`

--

  - NB: `R` is an "object-oriented language" (OOL)

--

  - We **create** an "object" to store the data using a left-arrow: `&lt;-`

--


``` r
df &lt;- read_rds('https://github.com/jbisbee1/ISP_Data_Science_2024/raw/main/data/sc_debt.Rds')
```


---

# Loading Data

--

- We now have the contents of `sc_debt.Rds` stored in the object `df`

--

  - This is a "tabular data frame", aka a `tibble`
  
  - **Rows** are observations
  
  - **Columns** are values

--

- We can look at this object directly


``` r
df
```

```
## # A tibble: 2,546 × 16
##    unitid instnm stabbr grad_debt_mdn control region preddeg
##     &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  
##  1 100654 Alaba… AL             33375 Public  South… Bachel…
##  2 100663 Unive… AL             22500 Public  South… Bachel…
##  3 100690 Amrid… AL             27334 Private South… Associ…
##  4 100706 Unive… AL             21607 Public  South… Bachel…
##  5 100724 Alaba… AL             32000 Public  South… Bachel…
##  6 100751 The U… AL             23250 Public  South… Bachel…
##  7 100760 Centr… AL             12500 Public  South… Associ…
##  8 100812 Athen… AL             19500 Public  South… Bachel…
##  9 100830 Aubur… AL             24826 Public  South… Bachel…
## 10 100858 Aubur… AL             21281 Public  South… Bachel…
## # ℹ 2,536 more rows
## # ℹ 9 more variables: openadmp &lt;int&gt;, adm_rate &lt;dbl&gt;,
## #   ccbasic &lt;int&gt;, sat_avg &lt;int&gt;, md_earn_wne_p6 &lt;int&gt;,
## #   ugds &lt;int&gt;, costt4_a &lt;int&gt;, selective &lt;dbl&gt;,
## #   research_u &lt;dbl&gt;
```

---

# Loading Data

--

- Or we can look at its columns


``` r
names(df)
```

```
##  [1] "unitid"         "instnm"         "stabbr"        
##  [4] "grad_debt_mdn"  "control"        "region"        
##  [7] "preddeg"        "openadmp"       "adm_rate"      
## [10] "ccbasic"        "sat_avg"        "md_earn_wne_p6"
## [13] "ugds"           "costt4_a"       "selective"     
## [16] "research_u"
```

---

# Loading Data

--



&lt;table class=" lightable-paper lightable-hover" style='font-size: 13px; color: black; font-family: "Arial Narrow", arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Name &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Definition &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; unitid &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Unit ID &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; instnm &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Institution Name &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; stabbr &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; State Abbreviation &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; grad_debt_mdn &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Median Debt of Graduates &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; control &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Control Public or Private &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; region &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Census Region &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; preddeg &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Predominant Degree Offered: Assocates or Bachelors &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; openadmp &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Open Admissions Policy: 1=Yes, 2=No, 3=No 1st time students &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; adm_rate &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Admissions Rate: proportion of applications accepted &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ccbasic &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Type of institution* &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; sat_avg &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Average SAT scores &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; md_earn_wne_p6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Average Earnings of Recent Graduates &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ugds &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Number of undergraduates &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; costt4_a &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Average cost of attendance (tuition-grants) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; selective &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Institution admits fewer than 10% of applications, 1=Yes, 0=No &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; research_u &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Institution is a research university, 1=Yes, 0=No &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;ast;&lt;font size="2"&gt;See [here](https://data.ed.gov/dataset/9dc70e6b-8426-4d71-b9d5-70ce6094a3f4/resource/658b5b83-ac9f-4e41-913e-9ba9411d7967/download/collegescorecarddatadictionary_01192021.xlsx)&lt;/font&gt;

---

# Manipulating the Data

--

- These data are cool!

--

- But TMI at first

--

- I want to know...

--

  - Where is `Vanderbilt University`?
  
--

  - Who is the most selective?
  
--

  - Which schools produce the richest grads?
  
--

- There are `tidyverse` functions to answer all of these questions

---

# Manipulating with `tidyverse`

- The code process of `tidyverse` relies on a "pipe" symbol: `%&gt;%`

--

  - I don't like this name
  
  - I think it should be called a "chain" because it **links code together**
  
  - Or maybe a "do" symbol because it tells `R` what to do
  
--

- The basic grammar of `R` is: object, `%&gt;%`, verb


``` r
object %&gt;%  # This is the object
   function() # This is the verb
```

---

# Manipulating with `tidyverse`

- `tidyverse` has many useful "verbs" (i.e., functions)

  - `filter()`: subsets **rows**
  
  - `select()`: subsets **columns**
  
  - `arrange()`: sorts **rows** based on **columns**
  
  - `summarise()`: collapses **rows**
  
  - `group_by()`: groups **rows** by **columns**
  
---

# Manipulating: `filter()`

- So let's look at Vandy

--

- `filter` will select **rows** of the data based on some criteria

--


``` r
df %&gt;%
  filter(instnm == "Vanderbilt University") # Only select rows with Vandy
```

```
## # A tibble: 1 × 16
##   unitid instnm  stabbr grad_debt_mdn control region preddeg
##    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  
## 1 221999 Vander… TN             14962 Private South… Bachel…
## # ℹ 9 more variables: openadmp &lt;int&gt;, adm_rate &lt;dbl&gt;,
## #   ccbasic &lt;int&gt;, sat_avg &lt;int&gt;, md_earn_wne_p6 &lt;int&gt;,
## #   ugds &lt;int&gt;, costt4_a &lt;int&gt;, selective &lt;dbl&gt;,
## #   research_u &lt;dbl&gt;
```

---

# Manipulating: `select()`

- Still TMI!

--

- I only care about the admissions rate (`adm_rate`), the SAT scores (`sat_avg`), and the future earnings (`md_earn_wne_p6`)

--

- `select` will select **columns**


``` r
df %&gt;%
  filter(instnm == "Vanderbilt University") %&gt;%
  select(instnm,adm_rate,sat_avg,md_earn_wne_p6) # Only select four columns
```

```
## # A tibble: 1 × 4
##   instnm                adm_rate sat_avg md_earn_wne_p6
##   &lt;chr&gt;                    &lt;dbl&gt;   &lt;int&gt;          &lt;int&gt;
## 1 Vanderbilt University   0.0912    1515          53400
```

---

# Manipulating: `arrange()`

- How does Vandy compare...?

--

  - to other schools in terms of SAT scores?
  
  - to other schools in terms of future earnings?
  
  - to other schools in terms of admissions rates?

--

- `arrange` will sort the data based on a column (ascending!)


``` r
df %&gt;%
  arrange(sat_avg) %&gt;% # Sort data by SAT scores
  select(instnm,sat_avg) # Only look at name and SAT scores
```

```
## # A tibble: 2,546 × 2
##    instnm                        sat_avg
##    &lt;chr&gt;                           &lt;int&gt;
##  1 Morgan State University           737
##  2 Saint Augustine's University      847
##  3 Albany State University           849
##  4 Holy Names University             851
##  5 Livingstone College               854
##  6 Virginia Union University         855
##  7 Manor College                     861
##  8 Saint Louis Christian College     865
##  9 Bacone College                    875
## 10 Paine College                     876
## # ℹ 2,536 more rows
```

---

# Manipulating: `arrange()`

- Vandy is not in the bottom 10 schools


``` r
df %&gt;%
  arrange(sat_avg) %&gt;% # Sort data by SAT scores
  select(instnm,sat_avg) # Only look at name and SAT scores
```

```
## # A tibble: 2,546 × 2
##    instnm                        sat_avg
##    &lt;chr&gt;                           &lt;int&gt;
##  1 Morgan State University           737
##  2 Saint Augustine's University      847
##  3 Albany State University           849
##  4 Holy Names University             851
##  5 Livingstone College               854
##  6 Virginia Union University         855
##  7 Manor College                     861
##  8 Saint Louis Christian College     865
##  9 Bacone College                    875
## 10 Paine College                     876
## # ℹ 2,536 more rows
```

---

# Manipulating: `arrange()`

- Use `desc()` to order in descending values...Vandy not in top 10 either


``` r
df %&gt;%
  arrange(desc(sat_avg)) %&gt;% # Sort data by SAT scores (descending)
  select(instnm,sat_avg) # Only look at name and SAT scores
```

```
## # A tibble: 2,546 × 2
##    instnm                                 sat_avg
##    &lt;chr&gt;                                    &lt;int&gt;
##  1 California Institute of Technology        1557
##  2 Massachusetts Institute of Technology     1547
##  3 University of Chicago                     1528
##  4 Harvey Mudd College                       1526
##  5 Duke University                           1522
##  6 Franklin W Olin College of Engineering    1522
##  7 Washington University in St Louis         1520
##  8 Rice University                           1520
##  9 Yale University                           1517
## 10 Harvard University                        1517
## # ℹ 2,536 more rows
```

---

# Manipulating: `arrange()`

- What if we look only at "selective" schools (i.e., those who accept less than 10% of applicants)?

--


``` r
df %&gt;%
  filter(adm_rate &lt; .1) %&gt;% # Only look at schools who accept less than 10%
  arrange(sat_avg,adm_rate) %&gt;% # Sort data by SAT scores AND THEN admissions rates (breaks ties)
  select(instnm,adm_rate,sat_avg) # Only look at name, admissions rate, and SAT scores
```

```
## # A tibble: 25 × 3
##    instnm                                   adm_rate sat_avg
##    &lt;chr&gt;                                       &lt;dbl&gt;   &lt;int&gt;
##  1 Colby College                              0.0967    1456
##  2 Swarthmore College                         0.0893    1469
##  3 Pomona College                             0.074     1480
##  4 Dartmouth College                          0.0793    1500
##  5 Stanford University                        0.0434    1503
##  6 Northwestern University                    0.0905    1506
##  7 Columbia University in the City of New …   0.0545    1511
##  8 Brown University                           0.0707    1511
##  9 University of Pennsylvania                 0.0766    1511
## 10 Vanderbilt University                      0.0912    1515
## # ℹ 15 more rows
```


---

# How does Vandy compare?

--

- `arrange` in descending order


``` r
df %&gt;%
  filter(adm_rate &lt; .1) %&gt;%
  arrange(desc(sat_avg),adm_rate) %&gt;%
  select(instnm,adm_rate,sat_avg)
```

```
## # A tibble: 25 × 3
##    instnm                                   adm_rate sat_avg
##    &lt;chr&gt;                                       &lt;dbl&gt;   &lt;int&gt;
##  1 California Institute of Technology         0.0642    1557
##  2 Massachusetts Institute of Technology      0.067     1547
##  3 University of Chicago                      0.0617    1528
##  4 Duke University                            0.076     1522
##  5 Rice University                            0.0872    1520
##  6 Harvard University                         0.0464    1517
##  7 Princeton University                       0.0578    1517
##  8 Yale University                            0.0608    1517
##  9 Vanderbilt University                      0.0912    1515
## 10 Columbia University in the City of New …   0.0545    1511
## # ℹ 15 more rows
```



---

# More complicated? More `%&gt;%`!

--

- Less selective schools by SAT with debt and state


``` r
df %&gt;%
  filter(adm_rate &gt; .2 &amp; adm_rate &lt; .3) %&gt;% # Less selective schools (accept between 20% and 30%)
  arrange(stabbr,desc(sat_avg)) %&gt;% # Sort by state name, then by SAT scores
  select(instnm,sat_avg,grad_debt_mdn,stabbr) # Only look at some columns
```

```
## # A tibble: 37 × 4
##    instnm                       sat_avg grad_debt_mdn stabbr
##    &lt;chr&gt;                          &lt;int&gt;         &lt;int&gt; &lt;chr&gt; 
##  1 Heritage Christian Universi…      NA            NA AL    
##  2 University of California-Sa…    1370         15000 CA    
##  3 California Polytechnic Stat…    1342         19501 CA    
##  4 University of California-Ir…    1306         15488 CA    
##  5 California Institute of the…      NA         27000 CA    
##  6 University of Miami             1371         17125 FL    
##  7 Georgia Institute of Techno…    1418         23000 GA    
##  8 Point University                 986         26000 GA    
##  9 Grinnell College                1457         17500 IA    
## 10 St Luke's College                 NA         17750 IA    
## # ℹ 27 more rows
```

---

# A quick aside on missingness

--

- Some rows have `NA` in some columns

--

  - `NA` is the standard code for **missing data** in `R`
  
  - Data can be missing for many different reasons (i.e., some schools don't require SAT scores or record them)
  
  - We can use a base `R` function called `is.na()` which will be `TRUE` if the value is `NA` or `FALSE` otherwise
  
--

  - And we can combine `is.na()` with the `filter()` function from `tidyverse`

--

- We will return to this in the lectures on **data wrangling**
  
--

- For now, how many schools don't report SAT scores?


``` r
df %&gt;%
  filter(is.na(sat_avg)) %&gt;% # Only look at schools that DON'T report SATs
  select(instnm,stabbr) # Only look at the name and the state
```

```
## # A tibble: 1,317 × 2
##    instnm                                         stabbr
##    &lt;chr&gt;                                          &lt;chr&gt; 
##  1 Amridge University                             AL    
##  2 Central Alabama Community College              AL    
##  3 Athens State University                        AL    
##  4 Chattahoochee Valley Community College         AL    
##  5 Coastal Alabama Community College              AL    
##  6 Gadsden State Community College                AL    
##  7 George C Wallace State Community College-Selma AL    
##  8 Heritage Christian University                  AL    
##  9 Jefferson State Community College              AL    
## 10 Lurleen B Wallace Community College            AL    
## # ℹ 1,307 more rows
```


---

# Stepping back

--

- Thus far, lots of .red[data]

--

- Not a lot of .blue[science]

--

- But remember the .blue[Research] camp!

--

  1. .red[Observation] &amp;rarr; .blue[Question]

  2. .blue[Theory] &amp;rarr; .blue[Hypothesis]

  3. .red[Data Collection / Wrangling] &amp;rarr; .red[Analysis]

  4. .red[Results] &amp;rarr; .blue[Conclusion]
  
--

- We have been doing lots of .red[Observation]!

--

- Do we have any good .blue[Research questions]?

---

# Stepping back

- .blue[RQ]: How might admissions and SAT scores be **related**?

--

  - .blue[Theory]: selective schools have stricter criteria
  
--

  - .blue[Hypothesis]: admissions and SAT scores should be **negatively** related
  
--

- How can we test this hypothesis?


---

# Summarizing Data: `summarise()` + `mean()`

--

- We can combine base `R` functions with `tidyverse` functions!

--

  - Base `R`: `mean()`
  
  - `tidyverse`: `summarise()` (aka `summarize()`)
  
- Overall average SAT scores


``` r
df %&gt;%
  summarise(mean_sat = mean(sat_avg,na.rm=T)) # Average SAT scores for entire data
```

```
## # A tibble: 1 × 1
##   mean_sat
##      &lt;dbl&gt;
## 1    1141.
```

---

# Summarizing Data

--

- Let's unpack this


``` r
df %&gt;%
  summarise(mean_sat = mean(sat_avg,na.rm=T))
```

--

  - Create new variable `mean_sat` that contains the `mean()` of every school's average SAT score
  
--

  - `na.rm=T` means we want to ignore missing data. If not?
  
--
  

``` r
df %&gt;%
  summarise(mean_sat = mean(sat_avg))
```

```
## # A tibble: 1 × 1
##   mean_sat
##      &lt;dbl&gt;
## 1       NA
```

---

# Summarizing Data

--

- Recall we want see if more selective schools have higher SAT scores

--


``` r
df %&gt;%
  filter(adm_rate &lt; .1) %&gt;% # Only look at schools who accept less than 10% of applicants
  summarise(mean_sat_LT10 = mean(sat_avg,na.rm=T)) # Calculate the average SAT score
```

```
## # A tibble: 1 × 1
##   mean_sat_LT10
##           &lt;dbl&gt;
## 1         1510.
```


``` r
df %&gt;%
  filter(adm_rate &gt; .1) %&gt;% # Only look at schools who accept more than 10% of applicants
  summarise(mean_sat_GT20 = mean(sat_avg,na.rm=T)) # Calculate the average SAT score
```

```
## # A tibble: 1 × 1
##   mean_sat_GT20
##           &lt;dbl&gt;
## 1         1135.
```

---

# Summarizing Data: `group_by()`

--

- One final `tidyverse` function: `group_by()`

--

- There is a column called `selective` which is either 1 or 0

--

  - 1: the admissions rate is less than 10%
  
  - 0: otherwise
  
--


``` r
df %&gt;%
  select(instnm,selective,adm_rate)
```

```
## # A tibble: 2,546 × 3
##    instnm                              selective adm_rate
##    &lt;chr&gt;                                   &lt;dbl&gt;    &lt;dbl&gt;
##  1 Alabama A &amp; M University                    0    0.918
##  2 University of Alabama at Birmingham         0    0.737
##  3 Amridge University                         NA   NA    
##  4 University of Alabama in Huntsville         0    0.826
##  5 Alabama State University                    0    0.969
##  6 The University of Alabama                   0    0.827
##  7 Central Alabama Community College          NA   NA    
##  8 Athens State University                    NA   NA    
##  9 Auburn University at Montgomery             0    0.904
## 10 Auburn University                           0    0.807
## # ℹ 2,536 more rows
```

---

# Summarizing Data: `group_by()`

- Instead of running two separate `filter()` commands, use `group_by()`

--


``` r
df %&gt;%
  group_by(selective) %&gt;% # Group the data by selective (either 1 or 0)
  summarise(mean_sat = mean(sat_avg,na.rm=T)) # Calculate average SAT for each group
```

```
## # A tibble: 3 × 2
##   selective mean_sat
##       &lt;dbl&gt;    &lt;dbl&gt;
## 1         0    1135.
## 2         1    1510.
## 3        NA     NaN
```

---

# Results

- Do more selective schools have higher SAT scores?

--

- Yes

--

- This .red[Result] **confirms** our .blue[Hypothesis] and **answers** our .blue[Research Question]

---

# Conclusion

--

- What we've done today is a microcosm of data science

--

  1. Opened .red[data] (`readRDS`)
  
--
  
  2. Looked at .red[data] (`tidyverse` + `select()`, `filter()`, `arrange()`)
    
--

  3. Generated .blue[hypotheses] (Admissions versus SAT scores)
  
--

  4. .red[Tested] .blue[hypotheses] (`summarise()` + `mean()`)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
